{"url": "https://lesmoutonsenrages.fr/2017/02/21/les-risques-existentiels-encourus-par-lhumanite-une-evaluation/", "title": "Les risques existentiels encourus par l\u2019humanit\u00e9 : une \u00e9valuation\u2026. ", "author": "Volti Modifier l'article ", "date": "2017", "content": " Img/Wired:Quelques membres du CSER dans la prestigieuse biblioth\u00e8que de l\u2019Universit\u00e9 d\u2019Oxford qui sent l\u2019encaustique et le vieux parchemin. De gauche \u00e0 droite Julius Weitzd\u00f6rfer du CSER, Beth Barnes de la Future of Sentience Society, Stephen Cave du Leverhulme Center for Future Intelligence, Anders Sandberg, \u00e9crivain futuriste, Huw Price de l\u2019Universit\u00e9 de Cambridge et Jane Heal du CSER. Un petit groupe d\u2019universitaires comprenant des math\u00e9maticiens, des biologistes, des informaticiens, des juristes ou encore des philosophes a constitu\u00e9 \u00e0 l\u2019Universit\u00e9 de Cambridge une \u00e9quipe tr\u00e8s sp\u00e9ciale dont la mission est d\u2019\u00e9tudier les risques existentiels, en d\u2019autres termes les menaces auxquelles l\u2019humanit\u00e9 peut \u00eatre confront\u00e9e dans un futur ind\u00e9termin\u00e9. Tous les aspects de la politique, des sciences et des technologies ont \u00e9t\u00e9 abord\u00e9s par ce centre pour l\u2019\u00e9tude des risques existentiels (CSER, acronyme de Center for the Study of Existential Risk). Selon les \u00e9valuations qui ressortent de leurs travaux il est urgent de sensibiliser l\u2019opinion au sujet de ces risques qui ne sont pas ceux que l\u2019on croit commun\u00e9ment. # 1 Intelligence artificielle Le plus grand risque que court l\u2019humanit\u00e9 serait l\u2019intelligence artificielle prise globalement, non pas seulement des super-ordinateurs dans lesquels des algorithmes complexes influencent nos choix, ce qui est d\u00e9j\u00e0 le cas avec Google, ayant pour cons\u00e9quence un appauvrissement de notre libert\u00e9 de d\u00e9cision, mais \u00e9galement les machines consid\u00e9r\u00e9es globalement en particulier les robots. Le risque serait, si aucun contr\u00f4le n\u2019est organis\u00e9 \u00e0 l\u2019\u00e9chelle plan\u00e9taire d\u00e8s aujourd\u2019hui, une prise en otage de l\u2019ensemble de l\u2019humanit\u00e9. Les machines d\u00e9cideraient enti\u00e8rement pour nous. Ce n\u2019est pas de la science-fiction du genre \u00ab Terminator \u00bb mais bien une r\u00e9alit\u00e9 qui nous concerne tous et le CSER classe l\u2019intelligence artificielle comme la plus grande menace pour l\u2019humanit\u00e9 d\u00e8s 2075. # 2 Risque biologique Le d\u00e9veloppement inimaginable il y a encore 30 ann\u00e9es de la biologie moderne constitue le second plus grand risque pour l\u2019humanit\u00e9. Les outils modernes de la biologie mol\u00e9culaire ont ouvert la boite de Pandore. Les biologistes sont capables, notamment \u00e0 l\u2019aide de l\u2019outil CRISPR-cas9 de cr\u00e9er des virus nouveaux et de modifier des bact\u00e9ries anodines pour les transformer en facteurs pouvant provoquer une pand\u00e9mie totalement incontr\u00f4lable qui d\u00e9cimera en quelques ann\u00e9es l\u2019ensemble de l\u2019humanit\u00e9. Ce que craint le CSER est que la banalisation des outils de la biologie mol\u00e9culaire permette \u00e0 n\u2019importe quel biologiste un tant soit peu exp\u00e9riment\u00e9 de proc\u00e9der dans son garage \u00e0 ce genre d\u2019approche sans qu\u2019aucun contr\u00f4le puisse \u00eatre mis en place. Le risque biologique existe d\u00e9j\u00e0 et il est class\u00e9 comme tr\u00e8s \u00e9lev\u00e9. # 3 Les armes autonomes Ce risque, aussi, existe d\u00e9j\u00e0 : la perte de contr\u00f4le d\u2019armements intelligents. Juste un exemple pour situer ce risque. L\u2019arm\u00e9e sud-cor\u00e9enne surveille sa fronti\u00e8re la s\u00e9parant de la Cor\u00e9e du Nord \u00e0 l\u2019aide de robots construits par la firme Samsung. Ces machines sont capables de reconna\u00eetre un individu tentant de traverser cette fronti\u00e8re et de l\u2019abattre sans l\u2019autorisation d\u2019une hi\u00e9rarchie inexistante devenue inutile. Le CSER a imagin\u00e9 les pires scenarii. Il suffirait de quelques camions remplis de robots intelligents pour d\u00e9truire une ville enti\u00e8re. \u00c0 l\u2019extr\u00eame limite il deviendrait impossible d\u2019identifier l\u2019ennemi. Durant la guerre froide la strat\u00e9gie \u00e9tait d\u2019empiler des bombes nucl\u00e9aires pour dissuader l\u2019ennemi d\u2019attaquer. Aujourd\u2019hui il est tout \u00e0 fait r\u00e9aliste d\u2019imaginer des arm\u00e9es sans combattants, des machines feront le travail en lieu et place des combattants traditionnels. Ce risque de guerre robotis\u00e9e \u00e0 l\u2019aide de drones intelligents est d\u00e9j\u00e0 pr\u00e9sent et devra faire l\u2019objet de trait\u00e9s internationaux pour en limiter la port\u00e9e. C\u2019est l\u2019une des retomb\u00e9es majeures du risque # 1. # 4 Conflit nucl\u00e9aire Le CSER consid\u00e8re que le risque de conflit nucl\u00e9aire entre les deux puissances (USA et Russie) poss\u00e9dant \u00e0 elles deux plus de 90 % des armes nucl\u00e9aires existant dans le monde serait surtout la cons\u00e9quence d\u2019une fausse alerte. Statistiquement et selon les le\u00e7ons du pass\u00e9 la probabilit\u00e9 d\u2019une fausse alerte initiant par erreur un conflit nucl\u00e9aire conduisant \u00e0 la disparition de l\u2019humanit\u00e9 est de une fausse alerte tous les 14 ans. Il est donc loin d\u2019\u00eatre nul et l\u2019\u00e9quipe de Cambridge pr\u00e9conise une remise en question globale du risque de fausse alerte de la part des autorit\u00e9s russes et nord-am\u00e9ricaines mais aussi chinoises, pakistanaises et indiennes. Sachant qu\u2019un conflit nucl\u00e9aire g\u00e9n\u00e9ralis\u00e9 conduirait \u00e0 une destruction totale de l\u2019humanit\u00e9 le CSER classe pourtant ce risque comme peu \u00e9lev\u00e9. # 5 Risque climatique Pour le CSER le risque du changement climatique d\u2019origine humaine sur l\u2019organisation de la soci\u00e9t\u00e9 dans son ensemble doit \u00eatre pris en consid\u00e9ration mais il existe trop d\u2019incertitudes pour \u00e9valuer l\u2019ampleur de ce r\u00e9chauffement ainsi que son impact sur l\u2019humanit\u00e9. Si ce risque existe d\u00e9j\u00e0 il est class\u00e9 comme peu pr\u00e9occupant par cet organisme de prospective. # 6 Impact d\u2019un ast\u00e9ro\u00efde Consid\u00e9r\u00e9 comme probable au cours des 50 \u00e0 100 millions d\u2019ann\u00e9es \u00e0 venir, class\u00e9 tr\u00e8s faible mais potentiellement aussi d\u00e9vastateur que celui qui provoqua la disparition des dinosaures. # 7 Invasion d\u2019extra-terrestres Si la probabilit\u00e9 de formes de vie intelligentes dans l\u2019Univers n\u2019est pas nulle une invasion de la Terre par des extra-terrestres a \u00e9t\u00e9 consid\u00e9r\u00e9e par le CSER mais class\u00e9e impr\u00e9visible et extr\u00eamement faible, ouf ! # 8 Manque de nourriture et famines massives Compte tenu des pr\u00e9visions de croissance de la population mondiale \u2013 9,6 milliards d\u2019habitants en 2050 \u2013 le risque de famine est loin d\u2019\u00eatre n\u00e9gligeable d\u2019autant plus que l\u2019accroissement des rendements agricoles de pr\u00e8s de 70 % depuis la fin des ann\u00e9es 60 repose enti\u00e8rement sur la disponibilit\u00e9 en p\u00e9trole pour la production d\u2019engrais et de produits chimiques permettant de combattre les ravageurs. Cette am\u00e9lioration du rendement des cultures vivri\u00e8res a probablement atteint son maximum et le risque \u00e9tudi\u00e9 par le CSER est une attaque virale ou fongique massive de l\u2019une ou l\u2019autre des trois c\u00e9r\u00e9ales les plus cultiv\u00e9es dans le monde, riz, ma\u00efs ou bl\u00e9 qui provoquerait une famine aux cons\u00e9quences incontr\u00f4lables. La recherche et l\u2019am\u00e9lioration g\u00e9n\u00e9tique des plantes afin qu\u2019elles soient pr\u00e9munies contre de tels dangers biologiques para\u00eet n\u00e9cessaire sinon urgente. Le CSER a \u00e9valu\u00e9 la venue de ce risque majeur vers les ann\u00e9es 2050. # 9 La rumeur des acc\u00e9l\u00e9rateurs de particules Un accident dans un acc\u00e9l\u00e9rateur de particules comme celui du CERN \u00ab ferait \u00bb appara\u00eetre un petit trou noir qui finirait pas avaler tout ce qui l\u2019entoure et au final jusqu\u2019\u00e0 la Terre enti\u00e8re. Sur le papier ce serait en th\u00e9orie possible mais la probabilit\u00e9 qu\u2019un tel \u00e9v\u00e8nement puisse arriver reste du domaine de la pure sp\u00e9culation. # 10 Un tyran plan\u00e9taire L\u2019arriv\u00e9e d\u2019un homme \u00e0 la t\u00eate d\u2019une grande nation qui nierait les \u00e9vidences scientifiques et technologiques pour accaparer pour lui et ses complices l\u2019ensemble des richesses de la plan\u00e8te, une hypoth\u00e8se qui semble avoir \u00e9t\u00e9 abord\u00e9e par le CSER dans la foul\u00e9e de l\u2019\u00e9lection de Donald Trump qui a promis de mettre \u00e0 plat l\u2019affaire du r\u00e9chauffement climatique. Comme des dizaines de milliers de chercheurs universitaires vivent de cr\u00e9dits allou\u00e9s pour conforter l\u2019hypoth\u00e8se du r\u00e9chauffement climatique d\u2019origine humaine ils se sentent donc directement concern\u00e9s et \u00e0 leurs yeux un homme comme Donald Trump est dangereux car \u00ab il nie les \u00e9vidences scientifiques \u00bb. Cette \u00e9num\u00e9ration appelle quelques remarques. D\u2019abord le dixi\u00e8me risque me para\u00eet un peu sp\u00e9cieux. Qu\u2019un groupe d\u2019intellectuels consid\u00e8re que Donald Trump repr\u00e9sente un danger pour la communaut\u00e9 scientifique parce qu\u2019il doute de la v\u00e9racit\u00e9 de la th\u00e9orie du r\u00e9chauffement climatique d\u2019origine humaine me para\u00eet excessif. J\u2019aurais pr\u00e9f\u00e9r\u00e9 un classement diff\u00e9rent de ces risques en y incluant le risque d\u2019un refroidissement du climat n\u2019en d\u00e9plaise aux tenants du dogme du r\u00e9chauffement. La robotique, les machines intelligentes, les drones feront l\u2019objet d\u2019une \u00e9tude internationale et de la mise en place d\u2019un comit\u00e9 d\u2019\u00e9thique ad hoc pour r\u00e9guler les applications de ces technologies aussi bien que faire se peut de m\u00eame qu\u2019il existe des comit\u00e9s d\u2019\u00e9thique qui se penchent sur l\u2019utilisation des cellules embryonnaires humaines. Il s\u2019agira d\u2019une prise de conscience internationale quels que soient les int\u00e9r\u00eats industriels ou financiers en jeu. Personnellement je ne pense pas que l\u2019asservissement de l\u2019humanit\u00e9 toute enti\u00e8re par des machines puisse \u00eatre plausible ni possible \u00e0 moins que les hommes aient atteint un degr\u00e9 de d\u00e9g\u00e9n\u00e9rescence intellectuelle avanc\u00e9. Les deux risques les plus pr\u00e9occupants me paraissent \u00eatre une attaque des grandes cultures vivri\u00e8res par un ou des ravageurs incontr\u00f4lables comme c\u2019est d\u00e9j\u00e0 le cas pour les fr\u00eanes, les oliviers et les bananiers. Comme pour le phyllox\u00e9ra et la vigne, l\u2019ing\u00e9niosit\u00e9 humaine trouvera une parade mais un tel \u00e9v\u00e8nement laissera des traces douloureuses. Les risques \u00ab biologiques \u00bb pouvant se mat\u00e9rialiser par des exp\u00e9rimentations r\u00e9alis\u00e9es par un fou irresponsable sont \u00e9galement \u00e0 craindre mais mettre au point un virus hautement pathog\u00e8ne tuera son inventeur avant qu\u2019il ne se disperse dans la nature, un virus n\u00e9cessite un \u00ab r\u00e9servoir \u00bb et un vecteur. Je mettrai donc un gros b\u00e9mol dans l\u2019\u00e9valuation du risque # 2. Restent donc les risques # 5 et 8 qui se rejoignent dans le mesure o\u00f9 le refroidissement du climat annonc\u00e9 par de nombreux g\u00e9ophysiciens et astrophysiciens aura pour cons\u00e9quence une famine g\u00e9n\u00e9ralis\u00e9e et une totale et profonde d\u00e9sorganisation de l\u2019ordre mondial. Si j\u2019\u00e9tais membre du CSER je classerai ce risque en premi\u00e8re urgence car apparaissant en 2025 au plus tard comme l\u2019ont avanc\u00e9 des g\u00e9ophysiciens \u00e9minents.   Auteur et source Jacques Henry sur son Blog En effet, curieusement les volcans et les temp\u00eates solaires ont \u00e9t\u00e9 oubli\u00e9s dans cette \u00e9num\u00e9ration. L\u2019un des volcans les plus prometteurs pour ses effets catastrophiques en cas d\u2019explosion est le Yazur situ\u00e9 sur l\u2019\u00eele de Tanna au Vanuatu. Il y a pr\u00e8s de 20 ans il y avait au fond du crat\u00e8re de ce volcan un lac de lave permanent spectaculaire que j\u2019ai eu le privil\u00e8ge de voir \u00e0 plusieurs reprises. Il a disparu il y a quelques ann\u00e9es et la pression du magma ne cesse d\u2019augmenter. Quand ce volcan explosera, la moiti\u00e9 de l\u2019\u00eele de Tanna sera ray\u00e9e de la carte un peu comme ce qui eut lieu en 1452 ou 1453 dans le m\u00eame archipel au nord de l\u2019\u00eele d\u2019Efate.\nLorsque James Cook mouilla avec son bateau dont j\u2019ai oubli\u00e9 le nom dans la baie qu\u2019il appela \u00ab R\u00e9solution \u00bb juste au sud du Yazur il mesura une profondeur de 200 brasses soit environ 360 m\u00e8tres. Actuellement la profondeur de cette baie fr\u00e9quent\u00e9e par un troupeau de dugongs tr\u00e8s familiers n\u2019est que d\u2019une dizaine de m\u00e8tres ce qui signifie que la poche de magma a soulev\u00e9 le sud de l\u2019\u00eele de plus de 300 m\u00e8tres, ce qui est consid\u00e9rable en termes de temps g\u00e9ologique. Si le Yazur n\u2019arrive plus \u00e0 expulser de mati\u00e8re comme c\u2019\u00e9tait le cas il y a 20 ans il explosera. Et il s\u2019agira d\u2019un cataclysme plan\u00e9taire aussi d\u00e9vastateur que l\u2019explosion du Tambora \u2026 Jacques Henry Voir aussi: La Lune, Jupiter et l\u2019\u00c9pi de la Vierge La couleur des \u00e9colos Culture: L\u2019hygi\u00e8ne en Chine il y a 2000 ans Il y a 176000 ans les N\u00e9andertaliens \u00e9taient d\u00e9j\u00e0 \u00e9volu\u00e9s "}