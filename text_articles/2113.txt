Les glaces de l’Arctique au plus bas cet hiver Cette année, l’extension hivernale des glaces de l’Arctique est la plus faible jamais relevée depuis le début des mesures en 1979. C’est donc à un niveau nettement inférieur à la moyenne que va s’amorcer la fonte printanière. La saison d’extension de la glace de mer est apparemment terminée, selon les experts du Centre américain de données sur la neige et la glace (NSIDC). Mais ce pic d’extension des glaces de l’Arctique est bien bas avant le début de la période de fonte qui doit culminer en septembre. Il est même à un niveau record depuis le début des mesures satellites. Selon le dernier bulletin du NSIDC émis le 19 mars, la surface est donc moins étendue de 1,10 million de km2 par rapport à la moyenne de 15,64 millions km2 mesurée de 1981 à 2010. La superficie de la banquise a atteint 14,54 millions de km2 le 25 février, ce qui devrait être le maximum pour l’année. C’est 130 000 km2 de moins que le précédent record établi en 2011. Avec 14,91 millions de km², mars 2014 avait connu la 5è plus faible extension pour une fin de saison hivernale.  Cette année, le maximum a été atteint quinze jours plus tôt que la moyenne, qui survient autour du 12 mars, précise le NSIDC. Mais la date du pic d’extension est très variable selon les années. La formation de glace de mer arctique semble être terminée, même si une progression dans certaines régions n’est pas exclue. Il est possible que la banquise continue à s’étendre au cours des deux ou trois prochaines semaines. En tous cas, une nouvelle extension ne devrait pas permettre de dépasser la superficie atteinte le 25 février. Ces dernières décennies, l’Arctique est la région du globe où le réchauffement climatique s’est fait le plus sentir, élevant les températures à un rythme deux à trois fois plus rapide que sur le reste de la planète. En conséquence, la glace de mer de l’océan arctique s’est réduite de 30% par rapport au début des relevés satellites en 1979. L’Arctique affiche habituellement sa plus grande extension en mars et sa superficie la plus réduite en septembre. Dans les deux cas, la tendance est à la baisse. Mais c’est le niveau minimum constaté à la fin de l’été qui est le plus surveillé. C’est pour cette période là que le déclin de la glace de mer a été le plus impressionnant depuis le début des relevés en 1979. Le record de la plus faible extension au terme de la saison estivale a été établi en 2012. Il n’a pas battu cette année mais le NSIDC a quand même annoncé que le 6è plus bas niveau avait été atteint le 15 septembre 2014 avec 5,07 millions de km2. La circulation atmosphérique explique en partie le faible niveau d’extension de la glace de mer observé cette année. En raison des circonvolutions des vents de haute altitude, la chaleur a pu faire une incursion en Arctique côté Pacifique, ce qui a limité l’extension de la glace dans les mers de Bering et d’Okhotsk. C’est cette configuration qui a aussi favorisé des conditions chaudes dans l’ouest des Etats-Unis et la sécheresse en Californie. Début mars, le côté atlantique a également connu des températures plus élevées que la normale, jusqu’à +8°C dans la région de la mer de Barents, située à l’est du Groenland. Une des raisons pour lesquelles la diminution de la glace de mer est préoccupante, c’est que cette surface est très réfléchissante alors que l’océan liquide est très absorbant. Alors, quand la zone de couverture de la glace de mer est réduite, les rayons du soleil sont moins réfléchis vers l’espace. Cela signifie une plus grande absorption du rayonnement solaire par la Terre et un réchauffement climatique qui s’ajoute à celui des gaz à effet de serre. Ainsi, le réchauffement de l’Arctique est deux fois plus rapide que celui du reste du globe. Le réchauffement de l’Arctique favoriserait certains phénomènes climatiques extrêmes en Amérique du Nord, en Europe et en Asie, selon certains scientifiques. Jennifer Francis, de l’Université de Rutgers, est l’un des principaux défenseurs de cette thèse liant l’affaiblissement de la circulation atmosphérique aux hivers extrêmes. Normalement, la différence de température entre l’Arctique et les moyennes latitudes est telle que des vents de haute altitude extrêmement puissants, les jet streams, séparent la masse d’air polaire de celle du reste de l’hémisphère nord. Mais la différence de température s’amoindrit à la faveur du fort réchauffement de l’Arctique et les vents latéraux jouent moins leur rôle de barrière. Les jet streams sont moins rapides quand l’écart de température entre les deux masses d’air se réduit et tendent alors à onduler. De l’air polaire peut ainsi faire des incursions au sud tandis que de l’air chaud peut s’engouffrer dans le nord. C’est ce que l’on a vu ces hivers deniers dans l’est de l’Amérique du Nord. Jin-Ho Yoon, du Pacific Northwest National Laboratory, a proposé dans la revue Nature Communications un mécanisme légèrement différent pour expliquer le lien entre la fonte de la glace de mer et les vagues de froid en Amérique du Nord, en Europe et en Asie. Selon lui, la fonte de la glace de mer favorise un fort réchauffement local et cette chaleur se propage ensuite aux plus hautes couches de l’atmosphère, ce qui affaiblit les vents de haute altitude. Une étude récente publiée le 12 mars 2015 dans la revue Science montre que le réchauffement de l’Arctique risque surtout de conduire à des été caniculaires. Selon Dim Coumou, du Potsdam Institute for Climate Impact Research, l’augmentation des températures des hautes latitudes peut aussi induire des vagues de chaleur plus au sud en favorisant les situations de blocage atmosphérique. En cause, la réduction de l’activité des tempêtes en été, elle-même liée à une modification de la circulation atmosphérique. La glace de mer autour de l’Antarctique a atteint le 22 septembre 2014 un niveau d’extension record, selon le National Snow and Ice Data Center (NSIDC) américain. Le 22 septembre 2014, la glace de mer autour de l’Antarctique a atteint 20.11 millions de km2. Le précédent record datait de 2013 et cela fait maintenant plusieurs années que la glace de mer tend à progresser dans l’hémisphère sud. Cette évolution peut surprendre dans un contexte de réchauffement de la planète mais il pourrait bien s’agir d’une des manifestations des changements climatiques en cours. Le NSIDC avance plusieurs explications pour comprendre le phénomène. La force des vents est l’une des causes possibles. De forts vents du sud ont soufflé sur la mer de Weddell au cours du mois de septembre 2014. Les vents sont aussi renforcés par l’oscillation de l’Antarctique. Le vortex polaire s’est en effet intensifié depuis une trentaine d’années. Dans la phase positive de l’oscillation de l’Antarctique, les vents d’ouest se renforcent, favorisant l’empilement et l’épaississement de la glace. Les endroits où la glace a été balayée laissent alors à découvert l’océan dans des zones où il peut à nouveau geler en surface, selon une étude dirigée par Jinlun Zhang, chercheur à l’université de Washington. La destruction de la couche d’ozone est soupçonnée être liée au phénomène. En refroidissant la stratosphère, la perte d’ozone favorise les forts vents d’ouest et donc la constitution de glace de mer. L’autre cause évoquée est la fonte des glaciers qui libère une eau douce plus susceptible de geler. L’eau de fonte est en effet plus douce que l’eau de mer. L’extension de la glace de mer autour de l’Antarctique ne compense pas les pertes de l’Arctique, selon une nouvelle étude de la NASA. Dans l’ensemble, la planète a perdu de la glace de mer à un rythme annuel moyen de 35 000 km² depuis 1979. Même si la banquise antarctique a atteint un nouveau maximum record en septembre 2014, la baisse se poursuit au niveau mondial si l’on additionne les niveaux atteints dans les deux régions polaires. C’est la conclusion de l’étude de Claire Parkinson, chercheur au Goddard Space Flight Center de la NASA. La diminution de la banquise arctique dépasse de loin les augmentations de la banquise antarctique. La cause est sans nul doute le réchauffement accéléré de l’Arctique, dont le rythme est deux fois plus élevé que pour le reste de la planète. Lors de la première partie de l’année 2010, notamment, les températures ont été de 4°C supérieures à celles de la moyenne 1968-1996, selon la NOAA (météo américaine). Source : Johan Lorck, pour global-climat, le 21 mars 2015.  Source : Météo France, le 9 avril 2015. Record de chaleur pulvérisé en Californie au 1er trimestre 2015 L’année 2014 avait déjà été la plus chaude depuis le début des relevés météo en Californie mais ce début d’année (janvier-mars) est marqué par une anomalie positive encore plus importante, selon l’agence américaine NOAA. L’Etat est en même temps touché par une sécheresse exceptionnelle et l’approvisionnement en eau est menacé, le manteau neigeux des montagnes californiennes ayant quasiment disparu. Les hivers se suivent et se ressemblent aux Etats-Unis, avec un ouest chaud et un est glacial. C’est ce que l’on appelle le « dipôle » : des hautes pressions prévalent au nord-est de l’océan Pacifique tandis qu’une dépression permet à l’air arctique de s’engouffrer de l’autre côté du pays. Conséquence, les tempêtes hivernales bloquées par les hautes pressions sont déplacées bien au nord de la Californie, qui ne reçoit plus de pluies. L’Etat traverse ainsi une sécheresse depuis 4 ans, peut-être la pire des 1200 dernières années, selon une récente étude. Il y a déjà eu des périodes de précipitations déficitaires mais c’est surtout la conjonction avec des températures aussi élevées qui rend cette sécheresse exceptionnelle.  Moyenne des températures pour la période janvier-mars en Californie (Source : NOAA) Si l’air froid venu de l’Arctique a plongé dans l’est des Etats-Unis cet hiver, les températures les plus extrêmes ont été enregistrées dans l’ouest. Le climat est donc très contrasté dans le pays. Sur janvier-mars, New York et le Vermont ont connu des anomalies négatives record avec respectivement -3,8°C et -3,6°C. La Californie, de son côté, a enregistré sur la période janvier-mars un record de chaleur assez stupéfiant avec une anomalie positive de +4,2°C. On trouve de tel écarts à la moyenne dans tous les Etats de l’ouest américain : +4,3°C dans l’Idaho et l’Oregon et même +4,5°C dans le Nevada ! Il aura ainsi fait en moyenne 11,7°C sur les trois premiers mois de 2015 en Californie. Le précédent record avait été établi en 2014 avec 10,7°C sur janvier-mars. Sur l’ensemble du pays, les températures sont de +1,1°C par rapport à la moyenne malgré la vague de froid dans l’est. Reste maintenant à déterminer si cette configuration est liée au changement climatique. Dans une étude parue en septembre 2014, deux chercheurs de l’université de Stanford, Noah Diffenbaugh et Daniel Swain, affirmaient que la persistance et l’intensité du système de haute pression étaient inégalées depuis 1947, date des premières données disponibles sur la circulation atmosphérique. Des simulations climatiques ont été menées afin de déterminer comment pouvait évoluer le climat avec et sans accroissement de la quantité de gaz à effet de serre. Le résultat est que les systèmes de haute pression comme celui de 2013-2014 ont trois fois plus de chances de se produire sous le climat actuel que sous celui d’avant la révolution industrielle. Simon Wang, un chercheur de l’université de Utah State, a également découvert un possible lien entre le réchauffement climatique et les phénomènes comme la sécheresse en Californie, couplée à des vagues de froid dans l’est des Etats-Unis. Dans Geophysical Research Letters, l’étude de Simon Wang décrivait en mai 2014 un véritable jeu de dominos climatique favorisant l’existence de deux pôles, l’un formé par des hautes pressions dans l’ouest des Etats-Unis, l’autre formé par des basses pressions au niveau des Grands Lacs, dans l’est du pays. A l’origine de cette configuration, le réchauffement de l’ouest du Pacific tropical qui aurait perturbé la circulation atmosphérique de haute altitude jusqu’au nord-est du Pacifique, favorisant un système de haute pression dans cette région. Une théorie concurrente – ou complémentaire – impute la perturbation de la haute atmosphère au réchauffement de l’Arctique, susceptible également de conduire à des situations de blocage météo avec des canicules, des sécheresses ou des vague de froid. Cette idée est défendue par Jennifer Francis, spécialiste du climat à la Rutgers University. Avec l’arrivée annoncée d’un épisode El Nino, la Californie pouvait espérer des pluies mais finalement le phénomène a tardé à se manifester. S’il a été officiellement annoncé il y a quelques semaines, il est d’intensité modérée et n’a pas permis d’améliorer la situation. Près de la moitié de la Californie est encore dans un état de « sécheresse exceptionnelle », le niveau le plus sévère. En raison de la sécheresse, le gouverneur de l’Etat, Jerry Brown, a annoncé pour la première fois des restrictions d’eau, une décision inédite qui conduit les villes à abaisser leur consommation de 25%. Il n’y a quasiment plus de neige dans les montagnes de la Sierra Nevada, principal pourvoyeur en eau de la Californie. Les derniers relevés montrent que le déficit en couverture neigeuse a atteint un niveau record : seulement 5% de la moyenne. Le précédent record était de 25%. A Philips, la neige a même totalement disparu, un phénomène qui ne s’était jamais produit depuis 1941, date des premières mesures. Source : Johan Lorck, pour global-climat, le 11 avril 2015. GRAND FORMAT. Sécheresse aux USA : 18 alarmantes photos avant/après Face à une sécheresse historique, la Californie a annoncé, le 1er avril, des mesures d’urgence pour réduire de 25% la consommation d’eau. L’heure est grave : aucune trace de neige n’a été constatée à 2.000 mètres dans les montagnes de la Sierra Nevada. Une première en 75 ans. La pénurie n’est pas nouvelle. Depuis plusieurs années, elle frappe l’ouest des Etats-Unis, et l’été dernier, nous avions publié ce diaporama d’images comparant la situation au fil du temps sur plusieurs sites de la région. Alors que la situation ne fait qu’empirer, nous vous le reproposons. L’Enterprise Bridge passe au-dessus du lac Oroville, près du port de plaisance Bidwell, le 11 juillet 2011. Le plan d’eau, qui apparaît bien rempli, est le second plus grand réservoir de Californie. (Paul Hames/California Department of Water Resources via Getty Images) Trois ans plus tard, le 19 août 2014, le même lieu est presque à sec. La sécheresse dans l’ouest américain menace l’approvisionnement en eau dans cette région où vivent 40 millions de personnes, indique une étude parue fin juillet dans la revue « Geophysical Research Letters ». (Justin Sullivan/Getty Images/AFP) Haut niveau d’eau au port de plaisance Bidwell, au lac Oroville, le 20 juillet 2011, en Californie. (Paul Hames/California Department of Water Resources via Getty Images) Au même endroit, le 19 août 2014, soit trois ans plus tard, des terres naguère immergées ont surgi, réduisant considérablement la taille de la marina. (Justin Sullivan/Getty Images/AFP) Plein niveau d’eau au port de plaisance Bidwell, sur le lac Oroville, le 20 juillet 2011. (Paul Hames/California Department of Water Resources via Getty Images) Trois ans plus tard, le même site photographié le 19 août 2014. Grâce au système GPS, des scientifiques ont constaté que la sécheresse dans l’ouest des Etats-Unis entraîne une élévation du sol due aux pertes souterraines, a rapporté l’AFP le 22 août. (Justin Sullivan/Getty Images/AFP) Le Green Bridge, sur le lac Oroville, près du port de plaisance Bidwell, le 20 juillet 2011. (Paul Hames/California Department of Water Resources via Getty Images) Le niveau de l’eau est bien plus bas trois ans plus tard, le 19 août 2014. Au 26 août, le lac Oroville n’était rempli qu’à 31% de sa capacité de 4,3 kilomètres cubes, contre 47% en moyenne à cette époque de l’année. (Justin Sullivan/Getty Images/AFP) Vue resserrée du Green Bridge datant du 20 juillet 2011. (Paul Hames/California Department of Water Resources via Getty Images) Trois ans plus tard, le même Green Bridge sur un lac Oroville bien plus bas, le 19 juillet 2014. En janvier, le gouverneur de Californie a décrété l’état d’urgence en raison de la sécheresse, peut-être la plus grave depuis un siècle. Récoltes perdues, risques accrus de feux de forêt font partie du lot de calamités qu’une telle pénurie d’eau est susceptible de provoquer. (Justin Sullivan/Getty Images/AFP) Autre réservoir californien, le lac Folsom est ici vu à plein niveau, retenu par le barrage de Folsom, le 20 juillet 2011. (Paul Hames/California Department of Water Resources via Getty Images) Voici où en est la situation à Folsom trois ans plus tard, le 19 août 2014. Au 26 août, le réservoir n’était rempli qu’à 39% de sa capacité établie à 1,2 kilomètre cube, contre 62% en moyenne à cette date de l’année. (Justin Sullivan/Getty Images/AFP) Direction le lac Mead, réservoir de 36 kilomètres cubes qui alimente Las Vegas. Ici, des bateaux amarrés dans la marina de sa zone de loisirs, le 26 juillet 2007. (Ethan Miller/Getty Images) Le 17 juillet 2014, la marina a tout bonnement disparu et il n’y a guère plus de trace du lac à cet endroit. En fait, le port de plaisance a été déplacé dès 2008 en raison des faibles niveaux d’eau. (Ethan Miller/Getty Images/AFP) Des bateaux amarrés dans le port de plaisance du lac Mead, dans le Nevada, le 25 juillet 2007. (Ethan Miller/Getty Images) Le 17 juillet 2014, seuls deux locaux sanitaires sur des pontons flottants abandonnés rappellent qu’une marina existait naguère en ces lieux désormais asséchés. (Ethan Miller/Getty Images/AFP) Depuis l’espace également, la comparaison est saisissante. Ici, la Californie verdoyante sur une image satellitaire de la Nasa datant du 18 janvier 2013. (Nasa) Du marron à la place du vert, quasiment pas de neige sur la Sierra Nevada : la Californie a triste mine, le 18 janvier 2014, un an jour pour jour après le précédent cliché. Cliquez ici pour lire (en anglais) l’article que l’agence américaine consacre au phénomène. (Nasa) Source : L’Obs, le 4 avril 2015. P.S. Comme on l’a répété plusieurs fois, la quasi-totalité des climatologues spécialisées (voir ce billet par exemple, avec 97 % d’accord) sont d’accord et nous demandent d’agir pour ne pas prendre le risque de bouleverser le climat. Et comme le rappelle ici Jancovici, ou bien on croit un consensus scientifique (qui n’est jamais unanime à 100 %, ni une preuve absolue de vérité, le consensus pouvant toujours, un jour, à base de travaux sérieux, évoluer – mais pour 1 Galilée, il y a eu 1000 anti-Galilée expliquant après lui que la Terre était bien plate…) parce qu’on n’a pas d’autre choix, ou bien on perdra alors toute capacité d’aboutir à une certitude (certes relative et temporaire) permettant d’agir. Autrement dit, si le grand public décide de suivre les opinions ultra-minoritaires, il ne pourra plus décider, car il y aura toujours plein d’opinions ultra-minoritaires et leurs contraires simultanément. Ces opinions, importantes, doivent rentrer dans une méthode scientifique, à savoir être publiées dans des revues à comité de lecture, et se battre pour démontrer leur justesse et convaincre leurs pairs, aboutissant éventuellement à une modification du consensus… Bref, comme il y a un clair consensus (d’autant que, sachant que le CO2 est un important gaz à effet de serre, et qu’il y en a de plus en plus dans l’atmosphère et pas qu’un peu, le fait que ça se réchauffe est tout sauf surprenant…), je ferme les commentaires pour éviter le trollage…  97 % des climatologues spécialisés ne doutent donc pas du réchauffement… L’étude source Duran 2009 est téléchargeable ici. Elle se complète avec celle-ci Anderegg 2010. Une autre a été publiée en 2013 : Cook et al. : « Entre 1991 et 2011, sur près de 4.000 articles (3.896 exactement) exprimant une opinion à ce sujet et écrits dans des revues scientifiques à comité de lecture par des chercheurs du même domaine (« évaluation par les pairs ») par plus de 10.000 scientifiques (10.188), 97,1% entérinent la thèse de l’origine humaine du changement climatique ». Pour comprendre la stratégie classique à l’oeuvre ici (semer le doute pour paralyser la prise de décision) déjà utilisée sur le tabac ou la couche d’ozone, je vous renvoi sur ce billet indispensable : [Livre exceptionnel] Les marchands de doute, de Naomi Oreskes et Erick Conway P.S. Comme on l’a répété plusieurs fois, la quasi-totalité des climatologues spécialisées (voir ce billet par exemple, avec 97 % d’accord) sont d’accord et nous demandent d’agir pour ne pas prendre le risque de bouleverser le climat. Et comme le rappelle ici Jancovici, ou bien on croit un consensus scientifique (qui n’est jamais unanime à 100 %, ni une preuve absolue de vérité, le consensus pouvant toujours, un jour, à base de travaux sérieux, évoluer – mais pour 1 Galilée, il y a eu 1000 anti-Galilée expliquant après lui que la Terre était bien plate…) parce qu’on n’a pas d’autre choix, ou bien on perdra alors toute capacité d’aboutir à une certitude (certes relative et temporaire) permettant d’agir. Autrement dit, si le grand public décide de suivre les opinions ultra-minoritaires, il ne pourra plus décider, car il y aura toujours plein d’opinions ultra-minoritaires et leurs contraires simultanément. Ces opinions, importantes, doivent rentrer dans une méthode scientifique, à savoir être publiées dans des revues à comité de lecture, et se battre pour démontrer leur justesse et convaincre leurs pairs, aboutissant éventuellement à une modification du consensus… Bref, comme il y a un clair consensus (d’autant que, sachant que le CO2 est un important gaz à effet de serre, et qu’il y en a de plus en plus dans l’atmosphère et pas qu’un peu, le fait que ça se réchauffe est tout sauf surprenant…), je ferme les commentaires pour éviter le trollage…  97 % des climatologues spécialisés ne doutent donc pas du réchauffement… L’étude source Duran 2009 est téléchargeable ici. Elle se complète avec celle-ci Anderegg 2010. Une autre a été publiée en 2013 : Cook et al. : « Entre 1991 et 2011, sur près de 4.000 articles (3.896 exactement) exprimant une opinion à ce sujet et écrits dans des revues scientifiques à comité de lecture par des chercheurs du même domaine (« évaluation par les pairs ») par plus de 10.000 scientifiques (10.188), 97,1% entérinent la thèse de l’origine humaine du changement climatique ». Pour comprendre la stratégie classique à l’oeuvre ici (semer le doute pour paralyser la prise de décision) déjà utilisée sur le tabac ou la couche d’ozone, je vous renvoi sur ce billet indispensable : [Livre exceptionnel] Les marchands de doute, de Naomi Oreskes et Erick Conway 