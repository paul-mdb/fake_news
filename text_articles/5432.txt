Quelques enseignements du « hiatus » dans le réchauffement climatique Pourquoi le réchauffement atmosphérique global a-t-il ralenti de 1998 à 2012 ? Cette question, discutée à l’issue de la publication du 5e rapport du GIEC, a été récemment revisitée par les chercheurs du Centre national de recherches météorologiques – Groupe d’étude de l’atmosphère météorologique (Météo-France/CNRS). Les résultats confirment que la variabilité naturelle du Pacifique tropical joue un rôle majeur dans le ralentissement du réchauffement, mais relancent également le débat sur l’existence d’autres contributions et sur la manière d’évaluer la sensibilité des modèles aux forçages anthropiques. Ils impliquent par ailleurs une prochaine ré-accélération du réchauffement global. Ces travaux ont été publiés en ligne sur le site de Geophysical Research Letters le 16 février 2015. L’accumulation de gaz à effet de serre dans l’atmosphère provoque depuis la fin du 19e siècle un réchauffement global du système Terre, dont les mesures de température de l’air en surface restent l’un des indicateurs privilégiés au vu de la couverture spatio-temporelle et de la relative précision des instruments utilisés. Ces observations ont toutefois montré un net ralentissement du réchauffement global de 1998 à 2012 relativement à l’ensemble de la période 1951-2012Ce « hiatus » dans le réchauffement atmosphérique global peut paraître d’autant plus intriguant qu’il semble difficilement conciliable avec la plupart des simulations effectuées lors de la 5ème phase du projet d’intercomparaison des modèles de climat CMIP (qui a en partie servi de support à la rédaction du 5ème rapport du GIEC). Le ralentissement observé relève-t-il dès lors uniquement de la variabilité naturelle du climat ? Traduit-il aussi une mésestimation des forçages radiatifs anthropiques, voire une trop grande sensibilité des modèles à ces forçages ? Les travaux les plus récents sur ce thème tendent à privilégier la première piste, en désignant plus particulièrement le Pacifique tropical et le régime des alizés. Ce bassin océanique est en effet le siège d’une forte variabilité naturelle qui se manifeste aux échelles interannuelle (phénomène ENSO, pour El Niño/Southern Oscillation) et multi-décennale (PDO pour Pacific Decadal Oscillation) et se traduit notamment par de fortes fluctuations des vents dominants. L’hypothèse avancée est la suivante : l’intensification récente des alizés aurait provoqué un transfert de chaleur de la surface vers la subsurface de l’océan Pacifique tropical, via le renforcement des courants océaniques. Les chercheurs du CNRM-GAME se sont penchés sur la question en exploitant les simulations CMIP5 et en réalisant de nouvelles simulations visant à étudier plus spécifiquement le rôle du Pacifique tropical. Ces dernières ont été menées selon deux protocoles expérimentaux. Le premier consiste à piloter dans la simulation l’évolution des températures de surface de la mer de manière à la reproduire le plus fidèlement possible (y compris dans sa chronologie) et le second à piloter la dynamique de l’océan superficiel (via l’influence qu’ont sur elle les vents de surface) afin de privilégier le réalisme des échanges de chaleur entre l’atmosphère et l’océan. Les résultats des travaux menés au CNRM-GAME montrent que: – les études antérieures ont pu être biaisées par une surestimation de l’influence du Pacifique tropical sur la température du globe dans les modèles utilisés ; – l’influence du Pacifique tropical sur le réchauffement simulé par un modèle donné dépend en partie du protocole expérimental utilisé. Ils confirment toutefois l’importante contribution de la variabilité naturelle du Pacifique tropical au ralentissement récent du réchauffement global observé. Le réchauffement a dès lors vocation à s’accélérer au cours des prochaines décennies – à moins d’être entravé par un forçage externe, comme une éruption volcanique majeure. Source : Météo France, le 25 février 2015. Un réchauffement rapide après une pause climatique ? Depuis 1998, les températures ont augmenté moins vite que ne le prévoyaient les modèles. Même si 2014 a été marquée par un record de chaleur, la tendance décennale au réchauffement a été moins importante dans les années 2000 que dans les années 1990. Selon des scientifiques du Met Office et de l’Université d’Exeter, ce hiatus, sans doute lié à la variabilité naturelle du climat, a environ 15% de chances de se prolonger encore 5 ans. Une brutale phase de réchauffement devrait ensuite mettre un terme à cette pause. D’après les modèles climatiques, les températures sont censées augmenter de 0,2°C par décennie à cause du forçage des gaz à effet de serre. En raison de la variabilité naturelle du climat, ce réchauffement est plus ou moins marqué selon les décennies. Une nouvelle étude publiée dans Nature Climate Change analyse les chances pour que la variabilité du climat contrarie ponctuellement la tendance de fond au réchauffement climatique. Il s’avère que la variabilité naturelle a potentiellement la capacité de contrarier le rythme du réchauffement en annulant tout ou partie de la hausse décennale moyenne de 0,2°C annoncée par les modèles. Grâce à la puissance de calcul des modèles climatiques, les auteurs de l’étude ont pu déterminer que les périodes de hiatus climatiques d’une durée de 20 ans n’étaient susceptibles de se produire qu’une fois tous les 100 ans. Une fois qu’une pause est amorcée et qu’elle dure 15 ans, il y a ensuite 15% de chances pour qu’elle se poursuive encore 5 années supplémentaires. L’autre résultat important de l’étude est que les périodes de pause dues à la variabilité naturelle sont associées à l’enfouissement de chaleur dans l’océan. Lorsque se phénomène s’inverse, le largage de chaleur conduit à une phase de réchauffement rapide. La tendance décennale peut alors atteindre un rythme de 0,40°C, deux fois celui prédit par les modèles. Entre 1990 et 1999, les températures ont augmenté à un rythme de 0,25°C par décennie, selon les chiffres de la Nasa. Entre 2000 et 2009, ce rythme est retombé à 0,10°C par décennie et le réchauffement a même été quasiment nul entre 2003 et 2013. Si l’on considère que la variabilité naturelle du climat peut expliquer une baisse de 0,2°C des températures sur une dizaine d’années, cela signifie que la tendance moyenne au réchauffement (+0,2°C) peut être annihilée. Cela expliquerait pourquoi, depuis 1998, les températures onnt plafonné avec des conditions peu propices dans le Pacifique. Malgré cela, des records de chaleur ont quand même été battus en 2005, 2010 et 2014. Sans la variabilité naturelle, les records auraient été encore plus marqués. L’oscillation décennale du Pacifique (PDO) figure parmi les principaux candidats pour expliquer la pause. Il s’agit d’une variation de la température de l’océan Pacifique dont le cycle se déroule sur 15 à 30 ans. Dans sa phase positive, l’oscillation favorise les phénomènes El Niño, ce qui tend à réchauffer l’atmosphère. Mais après une période marquée par le largage de chaleur par l’océan, une phase de refroidissement prend le relais, c’est la phase négative de la PDO. Les conditions sont alors plus propices au phénomène La Niña.  La PDO était dans une phase négative avant 1976, puis dans une phase positive entre 1976 et 1998, une période qui a coïncidé avec une forte élévation des températures atmosphériques. Ensuite, une nouvelle phase négative a débuté en 1999, coïncidant avec la pause dans le réchauffement de la planète. Le rôle de la PDO semble confirmé par les résultats d’une étude publiée en janvier 2015 dans Nature Climate Change : les océans ont continué à se réchauffer entre 2006 et 2013, à un moment où les températures de l’air plafonnaient. Le réchauffement a été observé jusqu’à 2000 mètres de profondeur, confirmant que l’océan avait probablement absorbé une grande partie de la chaleur excédentaire due aux gaz à effet de serre. Entre la surface et 2000 mètres de profondeur, on a constaté depuis 2006 un réchauffement de 0,4 à 0,6 watts par mètre carré. Cette observation a pu être réalisée grâce au programme de développement des balises Argo qui enregistrent les températures dans les 2 premiers kilomètres. Une autre cause a été récemment avancée pour expliquer le hiatus du réchauffement climatique : le fait que les agences météo ne prennent pas suffisamment en compte les températures de l’Arctique dans le calcul de la température moyenne de la planète. Or il s’avère que les années 2000 ont été marquées par une forte élévation des températures de l’Arctique. Si on ne les prend pas en compte, on fausse partiellement la mesure de la moyenne mondiale. C’est ce qu’on noté les scientifiques Cowtan et Way, qui ont proposé une nouvelle méthode pour mieux prendre en compte la situation au pôle nord. Leur calcul de température a permis d’établir que le rythme du réchauffement était plus important (+0,16°C par décennie entre 2000 et 2009) que celui trouvé par les autres agences, surtout la NOAA et le Met Office, qui ne prennent pas assez en compte le climat des hautes latitudes. Quelles que soient les causes du hiatus climatiques, la tendance de long terme au réchauffement n’a pas été démentie par le ralentissement des années 2000. Si l’on prend en compte la période qui va des années 1970 à aujourd’hui, la tendance au réchauffement est conforme à ce que prévoient les modèles. L’étude parue dans Nature Climate Change montre en tous cas que le récent hiatus reste dans les limites des variations naturelles et que cette dynamique interne du climat ne peut pas être exclue comme une cause possible du moindre réchauffement climatique depuis 1998. Source : Johan Lorck, pour global-climat, le 26 février 2015. Confirmation du rôle du Pacifique dans les variations du climat Les émissions de gaz à effet de serre liées aux activités humaines favorisent l’élévation des températures sur le long terme. Mais le rythme de cette hausse varie sur des échelles de temps plus courtes en raison de causes naturelles. Parmi celles-ci, il y a les oscillations du Pacifique, de plus en plus suspectées d’être le principal facteur de modération du réchauffement ces 15 dernières années.  Entre 1990 et 1999, les températures ont augmenté à un rythme soutenu, de l’ordre de 0,25°C par décennie, si l’on prend comme référence les données de la Nasa. Mais entre 2000 et 2009, ce rythme s’est ralenti, retombant à 0,10°C par décennie, soit moins que les prévisions des modèles (0,20°C par tranche de dix ans). Dans le même temps, la planète est toujours en déséquilibre radiatif : en raison des gaz à effet de serre, il y a davantage d’énergie qui entre dans le système terrestre qu’il n’en ressort. Les données satellitaires montrent même une accélération de cette accumulation d’énergie entre la période 1985-1999 et 2000-2012. Dès lors, comment expliquer que ce déséquilibre radiatif ne se traduise pas par un réchauffement ? Où cette chaleur est-elle partie ? De nombreuses études ont tenté ces dernières années d’expliquer pourquoi la Terre s’était moins réchauffée que ne le prévoyaient les modèles depuis 1998. Michael Mann, climatologue à l’université de Pennsylvanie, assure que le réchauffement ne s’est pas arrêté : il a été atténué par des facteurs naturels… Mais temporairement. Sur la base d’une nouvelle étude publiée dans Science, il désigne le Pacifique comme principal responsable de la pause. Les modèles climatiques ne sont donc pas viciés, estime encore Michael Mann sur le site Realclimate. Dans leur enquête sur les variations naturelles du climat, Michael Mann et ses collègues Byron Steinman et Sonya Miller se sont concentrés sur l’hémisphère Nord et le rôle joué par deux des principales oscillations de températures de surface de la mer connues : l’Oscillation Atlantique Multidécennale ou « AMO » et l’Oscillation décennale du Pacifique ou « PDO ». Les températures moyennes de l’hémisphère Nord sont censées résulter d’une combinaison de l’AMO et de la PDO. Michael Mann et ses collègues ont utilisé une nouvelle méthode pour l’identification de ces oscillations, basée sur les simulations climatiques utilisées dans le plus récent rapport du GIEC. Grâce à ces simulations, il est possible d’estimer la composante des variations de température due à l’augmentation des concentrations de gaz à effet de serre, aux éruptions volcaniques et aux changements observés dans l’activité solaire. Lorsque l’on retire l’influence de ces différents facteurs sur les températures, on peut observer quel est le véritable poids des oscillations que sont l’AMO et la PDO. Il doit donc être possible de déterminer leur influence respective en écartant tout autre facteur agissant sur le climat. Les chercheurs ont constaté que l’état actuel des oscillations compensait une partie du réchauffement de l’hémisphère Nord. L’AMO semble avoir relativement peu joué sur les changements de température à grande échelle au cours des deux dernières décennies. Son amplitude a été faible, et elle est actuellement relativement plate. Dans le même temps, la PDO, a une tendance forte à la baisse. C’est donc la PDO (qui est liée à la prédominance des conditions froides de type La Niña dans le Pacifique tropical au cours de la dernière décennie) qui apparaît responsable du ralentissement de réchauffement. La PDO était dans une phase négative avant 1976, puis dans une phase positive entre 1976 et 1998, une période qui a coïncidé avec une forte élévation des températures atmosphériques. Ensuite, une nouvelle phase négative a débuté en 1999, coïncidant avec la pause dans le réchauffement de la planète. Il apparaît donc que le refroidissement naturel dans le Pacifique est le principal contributeur au ralentissement récent du réchauffement à grande échelle. Ce résultat confirme d’autres études récentes. Un article paru en février 2014 dans Nature Climate Change avait montré que les alizés exceptionnellement forts le long de l’équateur permettaient d’enfouir davantage de chaleur dans l’océan Pacifique tout en faisant remonter de l’eau froide à la surface plus à l’est. Il y a donc moins de chaleur disponible pour élever les températures de l’atmosphère, ce qui permet de compenser temporairement l’accumulation des gaz à effet de serre. Selon Matthew England, directeur de l’étude menée par l’université de New South Wales, les vents auraient eu un effet refroidissant de 0,1 à 0,2°C, un niveau permettant d’atténuer de 50% l’impact des gaz à effet de serre. Une autre étude parue dans Nature Geoscience montre que ce processus est déjà arrivé, mais dans la direction opposée : des vents plus faibles ont permis d’accélérer le réchauffement au début du 20è siècle. Lorsque les vents ont commencé à se renforcer après 1940, le réchauffement a ensuite ralenti. Des scientifiques du Centre national pour la recherche atmosphérique (NCAR) et de l’Université d’Arizona, emmenés par Diane Thompson, ont utilisé une nouvelle méthode basée sur l’analyse chimique du corail afin de reconstituer la configuration des vents tropicaux du Pacifique entre 1894 et 1982. Entre 1910 et 1940, les températures mondiales se sont élevées de 0,4°C alors que le forçage dû aux gaz à effet de serre d’origine humaine n’était que de 0,3 W m−2. Depuis 1970, on a constaté un réchauffement de 0,75°C mais avec un forçage beaucoup plus important, de l’ordre de 1,5 W m−2. Les vents du Pacifique seraient le facteur clé expliquant l’effet moindre des gaz à effet de serre lors de certains périodes. Des travaux conduits par Kevin Trenberth et John Fasullo, du Centre national pour la recherche atmosphérique (NCAR), montrent qu’il y a eu davantage d’enfouissement de chaleur dans le sous-sol de l’océan Pacifique au cours de ces 10 dernières années. Une autre étude réalisée par James Risbey démontre que les simulations des modèles qui suivent le plus fidèlement la séquence observée d’El Niño et La Niña durant la dernière décennie ont tendance à reproduire le ralentissement de réchauffement. James Risbey explique que sur le long terme les effets d’El Niño et La Niña s’annulent mais que ponctuellement ils peuvent expliquer des variations au niveau mondial. Certaines périodes, comme ces dernières années, ont été plus marquées par des événements de type La Niña qui tendent à refroidir la surface de l’océan Pacifique. D’autres explications ont été récemment évoquées pour expliquer la pause des températures. Parmi celles-ci, il y a la sous-estimation du réchauffement réel qui a eu lieu en raison de lacunes dans les données d’observation. Les années 2000 ont été marquées par une forte élévation des températures de l’Arctique. Si on ne les prend pas en compte, on fausse partiellement la mesure de la moyenne mondiale. C’est ce qu’on noté les scientifiques Cowtan et Way, qui ont proposé une nouvelle méthode pour mieux prendre en compte la situation au pôle nord. Leur calcul de température a permis d’établir que le rythme du réchauffement était plus important (+0,16°C par décennie entre 2000 et 2009) que celui trouvé par les autres agences, surtout la NOAA et le Met Office, qui ne prennent pas assez en compte le climat des hautes latitudes. Parmi les autres explications, on trouve aussi des facteurs naturels comme les petites éruptions volcaniques et la légère baisse de l’activité solaire qui ont eu une légère influence rafraîchissante sur le climat de la Terre. Si le Pacifique est le principal facteur expliquant la pause des températures, les prochaines années pourraient être marquées par un rythme de réchauffement plus soutenu. Le Bureau australien de météorologie vient de délivrer son dernier pronostic pour les chances de voir émerger un phénomène El Niño en 2015 : elles sont de l’ordre de 50%. Quand des conditions de type El Niño règnent sur le Pacifique, on l’a vu, les conditions sont propices à l’élévation des températures. Selon une étude statistique publiée récemment, le largage de chaleur lié à des conditions El Niño dans le Pacifique peut conduire à une phase de réchauffement rapide. La tendance décennale peut alors atteindre un rythme de 0,40°C, deux fois celui prédit par les modèles. Source : Johan Lorck, pour global-climat, le 3 mars 2015. Steinman, Mann et Miller à propos des oscillations de température entre Atlantique/Pacifique et l’Hémisphère Nord Pas de pause pour le réchauffement des profondeurs de l’océan Les océans ont continué à se réchauffer entre 2006 et 2013, selon une étude publiée dans Nature Climate Change. Le réchauffement a été observé jusqu’à 2000 mètres de profondeur, confirmant que l’océan avait probablement absorbé une grande partie de la chaleur excédentaire due aux gaz à effet de serre. Entre la surface et 2000 mètres de profondeur, on a constaté depuis 2006 un réchauffement de 0,4 à 0,6 watts par mètre carré. Cette observation a pu être réalisée grâce au programme de développement des balises Argo qui enregistrent les températures dans les 2 premiers kilomètres. Grâce à la l’utilisation de modèles océaniques, des chercheurs emmenés par Sybren Drijfhout, de l’Université de Southampton, avaient montré en 2014 que la chaleur emmagasinée par les océans entre les années 1990 et 2000 avait augmenté d’environ 0,7 Wm-2, mais avec une marge d’incertitude plus importante que dans la nouvelle étude. L’océan continue donc à emmagasiner de la chaleur à un rythme soutenu. 93% de l’énergie excédentaire reçue à la surface de la Terre en raison des gaz à effet de serre serait en effet absorbée par les mers du globe.  Les températures à la surface de la mer ont quand à elles augmenté de 0,1°C par décennie depuis 1951 mais il n’y a pas eu de tendance significative au réchauffement sur la période 1998-2013, précise la nouvelle étude parue dans Nature Climate Change. La situation a cependant évolué en 2014 puisque cette année a été marquée par les températures de surface de la mer les plus élevées jamais enregistrées, si l’on en croit notamment les données du Met Office. Avant le réchauffement de 2014, la pause dans les températures de surface de la mer constatée entre 1998 et 2013 serait due à des conditions de type La Niña dans le Pacifique. Les périodes où prévalent des épisodes La Niña sont marquées par un renforcement des vents d’est dans le Pacifique qui tendent à enfouir davantage de chaleur dans l’océan que lors des épisodes El Niño. Cependant, c’est la chaleur accumulée et non les températures de surface de le mer – où de l’atmosphère – qui reflètent le véritable déséquilibre radiatif de la Terre, rappellent les auteurs de l’étude. La grande variabilité des températures de surface de la mer montrent que c’est un piètre indicateur du réchauffement climatique. Car dans le même temps les satellites montrent que la Terre accumule davantage d’énergie qu’elle n’en émet, donc qu’elle est en déséquilibre radiatif. Si les températures de surface de la mer et de l’atmosphère augment lentement, on a désormais la confirmation que l’énergie excédentaire a en fait été enfouie dans les profondeurs de l’océan. La chaleur a été emmagasinée aussi bien dans la couche supérieure de l’océan, entre 0 et 500 mètres, que dans les couches plus profondes, entre 500 et 2000 mètres. Plus intéressant encore : si les températures de surface de l’océan ont suivi l’évolution dans le Pacifique entre les phase El Niño et La Niña, la couche située entre 100 et 500 mètres a connu une évolution opposée. Entre 0 et 500 mètres, l’océan s’est réchauffé de 0,005°C par an sur la période 2006-2013. Entre 500 et 2000 mètres, un réchauffement de 0,002°C par an a été observé. Entre 67 et 98% de l’accumulation de chaleur s’est faite dans les océans extratropicaux de l’hémisphère sud, notamment dans le Pacifique et l’océan indien, et dans une moindre mesure dans l’Atlantique sud. Source : Johan Lorck, pour global-climat, le 3 février 2015. P.S. Comme on l’a répété plusieurs fois, la quasi-totalité des climatologues spécialisées (voir ce billet par exemple, avec 97 % d’accord) sont d’accord et nous demandent d’agir pour ne pas prendre le risque de bouleverser le climat. Et comme le rappelle ici Jancovici, ou bien on croit un consensus scientifique (qui n’est jamais unanime à 100 %, ni une preuve absolue de vérité, le consensus pouvant toujours, un jour, à base de travaux sérieux, évoluer – mais pour 1 Galilée, il y a eu 1000 anti-Galilée expliquant après lui que la Terre était bien plate…) parce qu’on n’a pas d’autre choix, ou bien on perdra alors toute capacité d’aboutir à une certitude (certes relative et temporaire) permettant d’agir. Autrement dit, si le grand public décide de suivre les opinions ultra-minoritaires, il ne pourra plus décider, car il y aura toujours plein d’opinions ultra-minoritaires et leurs contraires simultanément. Ces opinions, importantes, doivent rentrer dans une méthode scientifique, à savoir être publiées dans des revues à comité de lecture, et se battre pour démontrer leur justesse et convaincre leurs pairs, aboutissant éventuellement à une modification du consensus… Bref, comme il y a un clair consensus (d’autant que, sachant que le CO2 est un important gaz à effet de serre, et qu’il y en a de plus en plus dans l’atmosphère et pas qu’un peu, le fait que ça se réchauffe est tout sauf surprenant…), je ferme les commentaires pour éviter le trollage…  97 % des climatologues spécialisés ne doutent donc pas du réchauffement… L’étude source Duran 2009 est téléchargeable ici. Elle se complète avec celle-ci Anderegg 2010. Une autre a été publiée en 2013 : Cook et al. : « Entre 1991 et 2011, sur près de 4.000 articles (3.896 exactement) exprimant une opinion à ce sujet et écrits dans des revues scientifiques à comité de lecture par des chercheurs du même domaine (« évaluation par les pairs ») par plus de 10.000 scientifiques (10.188), 97,1% entérinent la thèse de l’origine humaine du changement climatique ». Pour comprendre la stratégie classique à l’oeuvre ici (semer le doute pour paralyser la prise de décision) déjà utilisée sur le tabac ou la couche d’ozone, je vous renvoi sur ce billet indispensable : [Livre exceptionnel] Les marchands de doute, de Naomi Oreskes et Erick Conway 