par John Christy Directeur du Earth System Science Center, John R. Christy est professeur distingué en sciences de l’atmosphère et climatologue de l’État de l’Alabama à l’Université de l’Alabama à Huntsville, où il travaille depuis plus de 30 ans. Ses responsabilités comprennent la gestion d’un centre scientifique de plus de 80 employés, travaillant sur plusieurs projets de recherche allant de l’élaboration et du lancement d’instruments spatiaux à l’étude des impacts d’événements météorologiques importants dans les pays en développement, à des études à haute résolution de la pollution de l’air (chimie de l’air et météorologie). Ses recherches personnelles portent sur le développement, la construction et le perfectionnement de données climatiques mondiales et régionales qui peuvent servir à vérifier des affirmations relatives au climat, à sa variabilité et à la compréhension de la sensibilité du climat aux différents facteurs de forçage. Ce travail a donné lieu à près de 100 publications évaluées par des pairs. 1. Mesurer l’effet de serre Quand j’ai grandi, la science se définissait comme une méthode de recherche de la vérité. Vous émettiez une affirmation ou une hypothèse, puis deviez tester ou valider cette affirmation sur des données indépendantes de celles qui avaient servi à la formulation de l’hypothèse. Si cette validation échouait, votre hypothèse était rejetée et vous deviez repartir de zéro. En d’autres termes, votre hypothèse n’était pas une information validée. De nos jours, lorsque qu’une personne un affirme quelque chose sur le climat, et que quelqu’un comme moi infirme cette affirmation, cette personne plutôt que d’abandonner son hypothèse, va souvent se contenter de la proclamer plus haut et plus fort. Ces gens-là ont des difficultés à voir ce que les données montrent sur la non validité de leur hypothèse préférée. Je fais référence à la réponse du climat aux émissions supplémentaires de gaz à effet de serre venant de l’emploi de combustibles fossiles. Pour donner des ordres de grandeur (et c’est important) nous cherchons à déterminer l’impact sur le climat d’un « forçage » supplémentaire de 0,5 unité, pris parmi d’autres forçages, dont certains dépassent 100 unités. Nous essayons donc de comprendre l’effet d’une demi-unité supplémentaire ajoutée à des flux naturels d’énergie importants et variables. La figure 1 montre ce problème : le soleil en jaune envoie à la Terre 100 unités d’énergie par seconde, dont disons 70 sont absorbées, 23 par l’atmosphère et 47 par la surface. Il y a environ 750 millions d’unités dans une colonne d’atmosphère de surface un mètre carré : on parle donc de nombres fort petits par rapport au vaste réservoir de ces énergies.  Figure 1. L’effet de serre selon le GIEC AR5, figure 2.1 [NdT ceci est un ordre de grandeur par ciel clair sans nuage] L’énergie quitte la surface par différentes voies : l’évaporation de l’eau ou le flux résultant du contact avec l’air, mais le rayonnement infrarouge semble le plus grand. La surface envoie environ 105 unités [d’infrarouge thermique]  que l’atmosphère absorbe, mais l’atmosphère rayonne environ 100 unités vers la surface, de sorte que le bilan net entre les deux est de 5 unités. Environ 70 unités sont rayonnées vers l’espace, 58 émises par l’atmosphère et 12 directement par la surface. Ces 70 sont égales au flux solaire absorbé donc le système est en équilibre. La surface est, notons-le, également en équilibre, le nombre d’unités entrantes est égal au nombre d’unités sortantes. Le dioxyde de carbone supplémentaire que nous avons ajouté à l’atmosphère équivaut à environ 0,5 unité qui s’ajouterait aux 100 unités d’énergie rayonnées par l’air vers la surface. Nous essayons donc d’évaluer l’effet produit par cette petite quantité alors que nous avons des centaines d’unités qui vont et qui viennent, et qui, dans le temps, varient de bien plus que de la moitié d’une unité. En d’autres termes, l’évaporation peut être 24 un mois donné, mais  26 le mois suivant. Le rayonnement de la surface peut être 105 ou 102. Vous voyez donc que ce 0,5 d’une unité est presque égal au “bruit” du signal. La variable climatique que vous voulez étudier, pour voir où ces joules d’énergie se déposent et s’accumulent, est la température troposphérique. Vous voulez savoir ce que fait cette atmosphère épaisse : en effet si vous êtes dans l’espace et réglez votre œil sur les longueurs d’onde de l’énergie thermique et regardez à nouveau la Terre, c’est surtout l’atmosphère que vous verrez. C’est la “métrique” que nous voulons utiliser; nous en parlerons dans un instant. Regardons maintenant la surface, et imaginons-la comme un jeu où l’on tire sur une corde (Figure 2). A gauche l’équipe des bleus qui rend la surface plus froide ; ce sont les unités d’énergie qui quittent la surface. Celles-ci seront parfois plus importantes que les influences qui réchauffent, représentées par l’équipe rouge. Si ça se produit, la Terre refroidira. Mais quelques mois plus tard, les gars en rouge pourront tirer plus fort parce qu’ils ont plus de force : plus d’énergie est absorbée, et il y a un réchauffement. Le diagramme est à l’échelle : vous voyez que c’est le rayonnement infrarouge descendant qui est le plus gros puis le rayonnement solaire. A quoi ressemble notre demi-unité, la petite figure tout à droite ? Nous essayons de voir si ce minuscule bonhomme à droite compte dans ce jeu de Tir-à-la-corde de l’énergie à la surface.  Figure 2 Le réchauffement global en surface ressemble à un jeu de tir-à-la-corde 2. L’importance de la troposphère Il s’agit d’un problème difficile qui nécessite des mesures très précises. mais le problème peut être simplifié si l’on regarde la troposphère, qui émet vers le cosmos la majeure partie de la chaleur émise par la planète. En observant continûment les changements à cet endroit, nous pouvons en principe compter les joules d’énergie qui au fil du temps passent dans le système atmosphérique : c’est donc une mesure directe de l’effet de serre. Nous voulons savoir combien d’unités d’énergie sont collectées et accumulées dans l’atmosphère. En 1994, mon collègue Dick McNider et moi-même nous avons cherché à tester les modèles climatiques qui, à l’époque, indiquaient une vitesse de réchauffement de 0,35°C par décennie. C’est ce que disait le modèle de James Hansen, et ce que d’autres modèles disaient aussi. Dick et moi ne pensions pas probable cette valeur de Hansen, et ne faisions pas non plus confiance aux ensembles de données des températures de surface, parce sans mesure sur la plus grande partie de la surface de la Terre et parce que les enregistrements compilés n’étaient pas homogènes, ou dit autrement, les séries de mesures différent entre elles [par exemple pour les heures d’observation NDT]. Mais nous avions 15 années de données satellitaires, et avons pensé pouvoir peut-être en faire quelque chose. Il y avait aussi des problèmes avec les données satellitaires : elles sont affectées par les éruptions volcaniques et par les événements El Niño. Mais après avoir traité ces questions, nous sommes arrivés à une estimation de la tendance du réchauffement lié à l’effet-de-serre de 0,09◦C par décennie, soit environ le quart de la prévision des modèles climatiques. En 2017, Dick et moi avons voulu vérifier notre travail de 1994. Les séries temporelles étaient alors longues de 37,5 ans. La figure 3 montre les résultats. La ligne du haut représente la température réelle de la troposphère globale, la plage de l’étude originale de 1994 est la zone ombrée. Nous avons pu calculer et neutraliser l’effet El Niño qui explique une grande partie de la variabilité mais ne contribue pas à la tendance. Ensuite, il y a les deux creux de la température globale après les éruptions des volcans El Chichón et Pinatubo. Ces éruptions volcaniques envoient dans la stratosphère des aérosols qui rétrodiffusent la lumière du soleil et alors moins d’unités d’énergie entrent et la Terre se refroidit. J’ai développé une fonction mathématique pour simuler ça, comme le montre la figure 3 courbe d.  Figure 3. Mise à jour de la tendance redessiné d’après Christy et McNidder 2017 Après élimination de l’effet des volcans, il nous reste une ligne à peu près droite, à l’exception d’un peu de ” bruit ” résiduel. La tendance représentée par la ligne sombre de la figure 3-e, est 0,095°C par décennie, presque exactement la même que celle trouvée dans notre étude antérieure, il y a 25 ans. Dick et moi-même sommes très fiers de ce qu’un travail scientifique fait il y a si longtemps ait été confirmé et réaffirmé. La tendance au réchauffement que nous avons trouvée suggère que les hommes ont un impact relativement mineur sur les températures globales. Le GIEC nous dit le forçage sur ces 37,5 années, nous dit combien de molécules de gaz à effet de serre supplémentaires ont été émises et le forçage qu’elles représenteraient. Nous connaissons également l’effet des aérosols. De toutes ces données réunies, nous pouvons calculer ce que j’appelle -et nous avons été les premiers à utiliser ce terme la réponse climatique transitoire de la troposphère. En d’autres termes quel a été le changement de température dû à plus de forçage par les gaz à effet de serre. Ce calcul repose sur une hypothèse majeure, à savoir qu’il n’y a, dans les données de température [courbe e de la figure3], plus de variations naturelles résiduelles, en particulier qu’il n’y a pas de variations naturelles de long terme. C’est là une supposition fort hypothétique, mais qui nous a permis d’avancer. Notre résultat est que la réponse climatique transitoire (le réchauffement à court terme) dans la troposphère est +1.1°C pour un doublement de la concentration en dioxyde de carbone. Ce n’est pas bien alarmant. Si nous faisons le même calcul avec les résultats des modèles climatiques, nous obtenons +2. 31°C, valeur significativement différente. La réponse des modèles au dioxyde de carbone est le double de ce que nous constatons dans la réalité. 3. Une autre métrique Mais n’y-aurait-il pas une autre métrique, utilisable pour tester les modèles climatiques et leur réponse à ce forçage énergétique supplémentaire de 0,5 unité ? Ross McKitrick et moi en avons cherché une. Nous avions besoin d’une réponse aux forçages par les gaz à effet de serre présentant les caractéristiques suivantes : L’exigence (3) que les observations ne doivent pas avoir servi au calage du modèle élimine les observations de la température de surface qui, elles, servent au calage des paramètres ajustables pour régler et ajuster les résultats du modèle climatique. La métrique que nous avons finalement décidé d’utiliser est la température de l’atmosphère entre 30 000 et 40 000 pieds sous les tropiques de 20°N à 20°S. Pensez à un anneau d’air tout autour des tropiques (figure 4). La figure 5 est un exemple tiré du modèle climatique canadien. L’axe des abscisses représente la latitude, avec le pôle Nord à droite, le pôle Sud à gauche et les tropiques au milieu. L’axe des y est l’altitude. Les couleurs représentent différentes prévisions des tendances au réchauffement sur la période de 1979 à 2017. Et donc ce modèle climatique suggère qu’un réchauffement important aurait déjà dû se produire à une altitude comprise entre 30 000 et 40 000 pieds. C’est la grande zone rouge au centre. Vous venez de voir une représentation visuelle de la métrique que nous allons examiner. Les satellites mesurent les émissions micro-ondes de l’oxygène dans la bande de fréquences autour de 55 GHz, d’où l’on peut déduire une température. Les satellites mesurent de 20°N à 20°S et à différentes altitudes, comme montré par la colonne non ombrée au centre de l’image. Cela couvre le point rouge, ce qui signifie que nous pouvons tester l’hypothèse d’un réchauffement rapide entre 30 000 et 40 000 pieds.  Figure 4 La troposphère tropicale  Figure 5: Le “hot spot” prédit par le modèle canadien. L’axe des y est marqué en pression mais l’échelle le rend linéaire en altitude Presque tous les modèles montrent un tel réchauffement mais aucun ne le montre si le forçage supplémentaire des gaz à effet de serre n’est pas inclus. La figure 6 montre les tendances au réchauffement des 102 modèles climatiques dont la moyenne est de 0,44°C par décennie. C’est assez rapide : sur 40 ans, cela fait presque 2°C, bien que certains modèles aient un réchauffement plus lent et d’autres plus rapide. Cependant, le réchauffement du monde réel est beaucoup plus faible : il est environ un tiers de la moyenne du réchauffement des modèles.  Figure 6: Réchauffement de la troposphère tropicale en tendance [pente de la meilleure approximation linéaire] pour 102 modèles climatiques CMIP5 sur 1979–2017, 20°N–20°S, 300-200 hPa.  Figure 7:  Températures de la moyenne troposphère tropicale, modèles et observations. Modèles en rose, et divers ensembles d’observations dans des nuances de bleu. Lissage par moyenne sur 5 ans. 1979-2017. Les meilleures approximations linéaires de ces courbes passent toutes par le point {1979, 0} La figure 7 montre en rose les projections des modèles et les différents ensembles de données d’observation dans diverses nuances de bleu. Vous voyez facilement la différence des pentes des approximations linéaires ou tendance du réchauffement : les modèles chauffent trop vite. L’exception est le modèle russe qui est beaucoup moins sensible au dioxyde de carbone et qui donne donc pour la fin du siècle des projections qui sont bien loin d’être alarmantes. Les autres modèles sont déjà faux, et leurs prévisions pour 2100 ne sont pas fiables. Si un ingénieur construisait un avion en affirmant qu’il peut voler 600 milles mais qu’au au bout de 200 milles t avion s’écrase en panne de carburant, il ne dira pas : “Hé, je ne me suis trompé que d’un facteur 3“. On ne fait ça ni en ingénierie ni dans la vraie science. Un facteur trois est énorme dans un bilan énergétique. C’est pourtant ce qu’on a avec les modèles climatiques. Nous commençons à voir apparaître les premiers modèles de la prochaine génération, connus sous le nom de CMIP6. Ceux-ci serviront de base au prochain rapport d’évaluation du GIEC et à la définition des politiques climatique et énergétique des dix prochaines années. Malheureusement, ils ne paraissent pas avoir été améliorés comme le montre la figure 8 : les observations sont en bleu sur la gauche ; les modèles CMIP6 en rose, réchauffent plus vite que le monde réel. Leur sensibilité est de fait plus élevée encore que celles des modèles CMIP5 ; en d’autres termes, ils semblent pires que les précédents ! C’est un gros problème.  Figure 8: Réchauffement de la troposphère tropicale selon les modèles CMIP6. Tendance sur 1979–2014 (sauf pour le modèle le plus à droite qui s’arrête en 2007), pour  20°N–20°S, 300–200 hPa. Pourquoi en est-il ainsi ? La chaleur s’échappe vers l’espace en haut d’une colonne d’air qui traverse l’atmosphère. Dans les modèles climatiques si vous chauffez cette colonne d’air de 1°C, il n’y a que 1,4 W/m2 qui s’échappe dans l’espace. Mon collègue Roy Spencer a estimé que dans le monde réel c’est environ 2,6 W/m2 qui s’échappent dans l’espace. En d’autres termes, chaque fois qu’il y a un petit réchauffement, les modèles piègent trop de chaleur qui s’accumule avec le temps au lieu de s’échapper vers l’espace, comme c’est le cas dans la réalité. 4. Le GIEC cache ce problème Ces problèmes des modèles sont connus depuis longtemps. En 2000, j’ai participé à la rédaction d’un rapport parrainé par l’Académie nationale des sciences des États-Unis qui soulignait le décalage entre le réchauffement prévu par les modèles et celui du monde réel. Nous disions à l’époque : Un rapprochement plus correct des changements de températures des modèles et de ceux observés dépend de l’amélioration des modèles utilisés pour simuler la réponse atmosphérique aux forçages naturels et anthropiques. Comme on le voit, ce rapprochement ne s’est pas encore produit. Le GIEC est bien conscient du problème, mais dans son cinquième rapport d’évaluation (FAR, 2013) il a évité d’attirer l’attention sur ce point. Dans mes commentaires de relecture du rapport, j’ai souligné cette discordance et écrit que les affirmations du GIEC ne résisteraient pas à un examen contradictoire. Bien entendu, le processus de relecture du GIEC n’est pas un vrai examen contradictoire car les auteurs principaux [NDT lead authors], soigneusement sélectionnés pour que le « bon » message soit fourni, ont toujours le dernier mot. En réponse à mes objections, le GIEC a inséré un nouveau graphique, mais l’a enfoui dans les annexes, publiées longtemps après le rapport principal. C’est ce que montre la figure 9-a où l’on voit les tendances prévues et observées de la température dans l’atmosphère, de la surface à la stratosphère, et pour différentes bandes de latitudes. Intéressons-nous à la troposphère tropicale, qui est la zone mise en évidence par le graphique. La figure 9-b est un agrandissement de cette partie du graphique et est quelque peu simplifiée pour mieux faire voir la discordance. Plus on va vers la droite, plus le réchauffement est rapide et inversement vers la gauche pour le refroidissement. La couleur rouge représentent les modèles lorsqu’ils intègrent à la fois les forçages naturels et les forçages anthropiques ; la plage des observations est en gris. Il n’y a aucun chevauchement. Les modèles qui ne tiennent pas compte du forçage supplémentaire dû à ‘effet de serre sont en bleu. Ces séries en bleu prédisent fort bien le résultat réel, mais cela n’a jamais été mentionné nulle part dans le texte principal du rapport. La vitesse d’accumulation de joules d’énergie dans la troposphère tropicale est donc nettement inférieure aux prévisions des modèles climatiques CMIP5. Le prochain rapport du GIEC traitera-t-il de cette discordance qui perdure depuis si longtemps ? Il y a trois façons possibles de trancher cette question : Je prédis que l’option modèles invalidés ne sera pas retenue. C’est pourtant ce qu’il vous faudrait dire si vous suiviez une démarche scientifique.   