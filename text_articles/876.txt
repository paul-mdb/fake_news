Par Roy W. Spencer, Ph. D. Pour savoir dans quelle mesure le réchauffement climatique est d’origine anthropique, il faudrait connaître le réchauffement d’origine naturelle. Le GIEC estime que la variabilité naturelle est responsable de moins de la moitié du réchauffement observé depuis le milieu des années 1900, mais les politiciens, les activistes et les divers experts en énergie verte vont encore plus loin, tenant pour acquis que le réchauffement est entièrement dû aux activités humaines. Le fait est que malgré les théories qui abondent, à l’échelle de temps d’une vie humaine nous ne comprenons pas vraiment les causes du changement climatique naturel. Par exemple, il y a de nombreuses preuves que le petit âge glaciaire était réel, de sorte que le réchauffement des 150 dernières années (surtout avant 1940) pourrait être naturel, mais dans quelle proportion ? La réponse a d’énormes conséquences sur les politiques énergétiques à mener. Si l’ampleur  du réchauffement climatique n’était que de 50% de ce que prévoit le GIEC (ce qui ne représenterait que 20% du problème décrit par les médias et les politiciens), alors le coût énorme des énergies renouvelables peut être évité jusqu’à ce que nous disposions de technologies énergétiques compétitives. Le récent article sur le  « réchauffement planétaire confirmé par le système satellitaire AIRS » a utilisé 15 années de données satellitaires infrarouges pour obtenir une tendance au réchauffement de la surface plutôt forte (+0,24 °C par décennie). Des objections ont été apportées à cette étude par moi ici (traduction en français là NDT) et par d’autres, sur le fait notamment que la fin de la période étudiée ( 2003-2017 ) s’est terminée par un El Niño record en 2015-2016, ce qui signifie que la tendance au réchauffement au cours de cette période n’est pas entièrement d’origine anthropique. Si nous examinons le réchauffement observé sur la période de 19 ans allant de 2000 à 2018, nous constatons un événement El Niño record en 2015-2016 (toutes les anomalies mensuelles sont relatives au cycle saisonnier moyen de 2001-2017) :  Fig. 1. Tendances des températures moyennes mondiales au 21e siècle (en haut) en moyenne pour tous les modèles climatiques CMIP5 (en gris), les observations HadCRUT4 (en vert) et la température troposphérique UAH (en violet). L’indice ENSO multi varié (MEI, en bas) montre la tendance à la hausse de l’activité d’El Niño au cours de la même période, ce qui entraîne un renforcement naturel de la tendance au réchauffement observée. Nous constatons également que la moyenne des tendances de température de surface produites par tous les modèles CMIP5 (dont la plupart comporte une composante variabilité naturelle moyennée) montrent une tendance au réchauffement plus forte que les observations, malgré le renforcement de la tendance au réchauffement produite par l’événement El Niño de 2015-2016. Alors, quelle influence cet événement  « réchauffant » a-t-il eu sur les tendances calculées? Le moyen le plus simple de le savoir consiste à utiliser uniquement les données antérieures à cet événement. Pour rester aussi  objectif que possible, nous avons choisi la période de 15,5 années située entre 2000 et juin 2015 qui n’a pas été influencée par un événement El Niño ou La Nina :  Fig. 2. Comme sur la Fig. 1, mais pour la période de 15,5 ans allant de 2000 à juin 2015, période au cours de laquelle il n’y a eu aucune tendance de l’activité d’El Niño et de La Nina. On note que la tendance observée des températures de surface de HadCRUT4 est pratiquement divisée par 2 par rapport au réchauffement des modèle CMIP5 sur la même période et que la tendance de la température troposphérique de l’UAH est presque nulle. On peut se demander pourquoi la tendance UAH LT (basse troposphère) est si faible pour cette période, même si, sur la figure 1, elle n’est pas très inférieure aux observations de température de surface (+0,12 °C par décennie contre +0,16 ° C pour l’ensemble de la période allant jusqu’en 2018). J’ai donc examiné la version RSS LT (basse troposphère) de 2000 à juin 2015 qui présente une tendance de +0,10 C par décennie. Pour comparer ce qui est comparable, la température moyenne de la couche surface à 500 hPa (NDT 500 hpa = 5574 m) des modèles CMIP5 est en moyenne de +0,20 C par décennie, de sorte que même les données RSS LT (qui généralement présente une tendance plus chaude que celles d’UAH LT) n’est que la moitié de la tendance au réchauffement calculée par la moyenne des modèles CMIP5 au cours de cette période. Donc à la fin de la deuxième décennie du 21ème siècle, nous constatons encore que lorsque nous ignorons les fluctuations naturelles du système climatique (qui, parallèlement aux événements météorologiques violents, domine l’actualité du « changement climatique »), le taux de réchauffement observé n’est que de la moitié environ de celui projeté par les modèles climatiques. Cette fraction est en accord avec l’étude du budget énergétique global de Lewis & Curry (2018) qui analysait cent ans de changements de la température globale et du contenu calorifique des océans, et a également révélé que la « sensibilité climatique » ( en voir ici la définition NDT ) à l’augmentation du CO2 n’est que la moitié environ de ce que les modèles supposent. Il sera intéressant de voir si la nouvelle évaluation du modèle climatique (CMIP6) produit un réchauffement qui sera plus en phase avec les observations. D’après ce que j’ai entendu jusqu’à présent, cela semble peu probable. Si l’histoire peut être de quelque enseignement, cela signifie que les observations continueront à nécessiter des corrections pour s’ajuster aux modèles, et non l’inverse. 