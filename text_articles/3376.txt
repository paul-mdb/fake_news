Par le Dr Roy Spencer (Traduction du texte publié en anglais sur le blog du Dr Roy Spencer) De nombreux media ( CNN , BBC , Reuters) par exemple, ont déjà déclaré que le mois de juillet 2019 a été le mois le plus chaud jamais enregistré. On serait enclin à penser que dans la mesure cette assertion émane de sources gouvernementales officielles (telles que la NOAA et l’Organisation météorologique mondiale), les meilleures données ont été utilisées pour cette évaluation. Pourtant les déclarations officielles actuelles concernant les relevés de température globale proviennent d’un ensemble assez limité de mesures thermométriques sujettes à des erreurs et qui n’ont jamais été conçues pour mesurer les tendances de la température globale. Le réseau mondial de thermomètres de surface présente trois problèmes majeurs lorsqu’il s’agit de déterminer des températures moyennes globales:  (1) L’effet d’îlot de chaleur urbain (ICU) a provoqué un réchauffement progressif de la plupart des sites météorologiques terrestres en raison de l’imbrication de bâtiments, de parkings, de climatiseurs, de véhicules, etc. Ces effets sont localisés ne non pas représentatifs de la surface terrestre (qui reste majoritairement rurale), et ne sont pas causés par une augmentation du dioxyde de carbone dans l’atmosphère. Parce que le réchauffement dû à l’effet ICU « ressemble » au réchauffement climatique, il est difficile de l’extraire des données. En fait, les tentatives de la NOAA pour donner l’impression que les données contaminées par les effets ICU ressemblent aux données des zones rurales semblent avoir eu l’effet inverse. La meilleure stratégie consisterait simplement à n’utiliser que les meilleurs sites météorologiques (pour la plupart ruraux). Ce n’est actuellement pas le cas.  (2) Les températures des océans sont notoirement incertaines en raison de l’évolution des technologies utilisées pour mesurer la température (sauts en toiles jetés par-dessus bord pour recueillir un échantillon de mer, températures mesurées à la prise d’eau des moteurs des navires, plus récemment utilisation de bouées et depuis environ 1983 mesures par satellite). (3) Les températures des terres et des océans sont notoirement lacunaires sur le plan géographique. Comment estime-t-on les températures d’une zone de 1 million de milles carrés (2,5 millions de km2 NDT) dans laquelle aucune mesure n’est faite ? Il y a en réalité une meilleure façon de procéder. Une vision plus pertinente : les jeux de données de ré analyse globale Divers organismes de prévisions météorologiques à travers le monde ont des experts qui recueillent une grande variété de données auprès de nombreuses sources et déterminent quelles sont celles qui disposent d’informations sur la météo et celles qui n’en disposent pas. Mais comment font-ils la différence? Parce que de bonnes données produisent de bonnes prévisions météorologiques tandis que les mauvaises données n’en produisent pas. Les sources de données comprennent les thermomètres de surface, les bouées et les navires (utilisées pour le calcul de la température globale « officielle »), mais on y ajoute également des ballons météo, des données enregistrées par les avions commerciaux et une grande variété de sources de données par satellite. Pourquoi utiliserait-on des données qui ne sont pas de surface pour obtenir de meilleures mesures de la température de surface ? Étant donné que les conditions météorologiques en surface ont une incidence sur les conditions météorologiques dans les couches plus élevées de l’atmosphère (et inversement ), il est possible d’obtenir une meilleure estimation de la température moyenne globale à la surface si l’on dispose de mesures satellitaires des températures de l’air en altitude globales incluant les régions où il n’existe aucune donnée de surface. Il vaut mieux savoir s’il existe une masse d’air chaud ou froid à partir de données satellitaires que de ne rien savoir du tout. De plus, les systèmes météorologiques se déplacent. Et c’est tout l’avantage des jeux de données ré analysées : parce que toutes les diverses sources de données ont été étudiées en profondeur pour déterminer quelle combinaison de ces données produiront les meilleures prévisions météorologiques (y compris les ajustements pour corriger les biais instrumentaux possibles et leur dérive dans le temps), nous savons que la cohérence physique des différentes données d’entrées aura également été optimisée. Une partie de ce processus consiste à établir des prévisions pour obtenir des « données » là où aucune donnée n’existe. Étant donné que les systèmes météorologiques se déplacent continuellement dans l’espace, les équations de mouvement de thermodynamique et d’humidité peuvent être utilisées pour estimer les températures là où l’on ne dispose pas de données en effectuant une « extrapolation physique » à l’aide des données observées un jour dans une zone, puis en observant comment les caractéristiques atmosphériques sont transférées dans une zone sans données le jour suivant. C’est ainsi que nous savions qu’il y aurait des journées extrêmement chaudes en France récemment: il était prévu qu’une couche d’air chaud du Sahara se déplacerait du désert du Sahara vers l’Europe occidentale. Ce type d’extrapolation basé sur la physique (qui est à la base des prévisions météorologiques) est beaucoup plus réaliste que d’utiliser (par exemple) les températures de la surface des terres en juillet autour de l’océan Arctique simplement pour deviner les températures au-dessus des eaux froides de l’océan et de la glace, où les températures sont rarement au-dessus de zéro. C’est pourtant la façon de procéder discutable utilisée (par la NASA GISS) pour obtenir des estimations de la température en l’absence de données. A ceux  à qui la technique de ré analyse semble suspecte, je précise une fois de plus qu’elle est utilisée pour vos prévisions météorologiques quotidiennes. Nous nous plaisons à moquer la qualité médiocre de certaines prévisions météorologiques, bien qu’il soit évident que les prévisions sur 2 ou 3 jours sont assez précises et continuent de s’améliorer. Une photo de la ré analyse de juillet 2019 Les seules données de ré analyse que je connaisse qui soient disponibles au public presque en temps réel sont fournies par WeatherBell.com et proviennent de la version 2 du système de prévision climatique de la NOAA, (CFSv2). La carte des anomalies de température de surface juillet 2019 montre une température moyenne mondiales supérieure de 0,3 C (0,5 ° F) à la moyenne de la période 1981-2010 : On mesure à partir de cette carte à quel point les informations ont été déformées au sujet des épisodes temporaires de chaleur en France, qui selon les médias ont contribué à augmenter chaleur moyenne dans le monde. Oui, il a fait exceptionnellement chaud en France en juillet. Mais regardons la froidure de l’Europe de l’Est et de la Russie occidentale. La presse en a t-elle fait état ? sans parler du fait que les températures aux États-Unis ont été en moyenne au dessous la normale? La jeu de données de ré analyse CFSv2 ne remonte qu’à 1979 et nous a permis de découvrir que juillet 2019 était en réalité plus froid que 2016, 2002 et 2017, et qu’il serait donc le 4ème mois de juillet le plus chaud en 41 ans. Et n’étant seulement que de 0.3 °C supérieur à la moyenne, cela n’est somme toute pas terriblement alarmant. Nos mesures UAH de température de la troposphère inférieure  indiquaient que juillet 2019 était le troisième mois le plus chaud après 1998 et 2016, à + 0,38 C au-dessus de la normale. Pourquoi ceux dont la mission est de surveiller les températures globales n’utilisent-ils pas les jeux de données de ré analyse? La principale limitation des jeux de données de ré analyse est que la plupart d’entre eux ne remontent qu’à 1979, (et je crois) qu’au moins un remonte aux années 1950. Étant donné que ceux qui surveillent les tendances mondiales de la température veulent des données remontant aussi loin que possible (au moins jusqu’à 1900 ou même avant), ils peuvent légitimement vouloir construire leurs propres jeux de données à partir du plus long enregistrement de données disponible : soit à partir des thermomètres de surface. Mais l’essentiel du réchauffement s’est produit (sans doute) au cours des 50 dernières années, et si l’on essaie de relier la température globale aux émissions de gaz à effet de serre, la période écoulée depuis 1979 (les 40 dernières années) semble suffisante car c’est la période pendant laquelle les plus grosses émissions de gaz à effet de serre se sont produites et par conséquent où le réchauffement le plus important devrait être observé. Je suggère donc que les ensembles de données de ré analyse globale soient utilisés pour donner une estimation plus précise de l’évolution de la température mondiale dans le but de suivre les tendances du réchauffement au cours des 40 dernières années et au delà dans le temps. Ce sont clairement les ensembles de données qui sont les plus proches des lois de la physique, ayant été optimisés pour produire les meilleures prévisions météorologiques et qui sont les moins l’objet d’ajustements ponctuels pour obtenir ce que le fournisseur de données pense devoir être la réponse au lieu de laisser la physique de l’atmosphère décider. Une preuve que les températures globales basées sur ERA5 posent problème Roy Spencer a complété son article par une nouvelle publication le 6 août 2019 intitulée Evidence that ERA5-based Global Temperatures Have Spurious Warming Pour faire suite à mon précédent article qui traitait du point de savoir si juillet 2019 avait été le mois de juillet le plus chaud (en moyenne globale), j’ai comparé des ensembles de données de ré analyse remontant à 1979. Il semble que la ré analyse de l’ERA5 sur laquelle reposent les prévisions de température de l’OMM posent problème, avec une chaleur parasite dans les années récentes. Voici une comparaison des variations de la température de l’air moyenne mondiale à la surface issues de trois ensembles de données de ré analyse: ERA5 (ECMWF), CFSv2 (NOAA / NCEP) et MERRA (NASA / GSFC). Notez que seul CFSv2 couvre toute la période, de janvier 1979 à juillet 2019: ERA5 montre une tendance au réchauffement plus forte que les deux autres. En différenciant ERA5 des autres jeux de données, on peut constater que certains changements systématiques se produisent dans ERA5, en particulier après 1998 et vers 2009-2010. Ces changements suggèrent qu’il y a des différences dans la manière dont les mesures satellitaires des températures des couches épaisses de l’air MSU et AMSU sont traitées, ce qui au travers du processus d’assimilation des données, peut affecter les températures de surface. La dépendance des ensembles de données de ré analyse aux diverses sources de données est difficile à diagnostiquer car une grande variété de données y est incluse : thermomètres de surface, ballons météorologiques, aéronefs, navires, bouées et divers satellites. Étant donné que les satellites constituent la seule source véritablement globale, ils peuvent impacter significatif les mesures moyennes globales. Si les satellites s’avèrent être la raison principale de ces différences, cela signifie que la façon dont les satellites sont ajustés à mesure que les orbites s’affaissent, sont inter-calibrés les uns par rapport autres et même si certains satellites problématiques  sont exclus de l’analyse, tous deviennent des facteurs importants dans l’interprétation des températures moyennes mondiales issues des ré analyses. Par exemple, la déclaration de l’ OMM selon laquelle le mois de juillet atteindrait ou aurait presque atteint un record de chaleur (basé sur la ré analyse de l’ERA5) dépendrait alors de la manière dont ses données satellitaires ont été calibrées. En conséquence, je retire ma récente assertion selon laquelle les jeux de données de ré analyse actuels devraient être utilisés pour déterminer les mois les plus chauds. À ce stade, je ne suis même pas certain que les jeux de données de ré analyse soient meilleurs pour déterminer les records de hausse (ou de baisse) des températures de surface que notre jeu de données satellite (UAH), même si le satellite mesure beaucoup plus la température de la troposphère que celle de la surface. Tout cela est très préliminaire et je suis ouvert à d’autres interprétations. 