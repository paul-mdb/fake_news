Le rapport spécial sur le réchauffement planétaire de 1,5 ° C a été approuvé par le GIEC samedi 6 octobre 2018 à Incheon, en République de Corée. Un rapport de 400 pages, résultat du travail de 91 auteurs de 40 pays, et des apports de 133 contributeurs qui ont passé en revue 6000 publications scientifiques a expliqué Mme Valérie Masson-Delmotte (coprésidente du groupe de travail numéro 1 du GIEC) lors de son audition au Sénat. Les principales conclusions du rapport principal sont condensées dans un  Résumé pour décideurs  document de 34 pages censé guider l’actions des gouvernements. Que dit ce rapport ? D’abord que les activités humaines ont provoqué un réchauffement de la planète d’environ 1,0 ° C par rapport aux niveaux préindustriels (fourchette probable de 0,8 ° C à 1,2 ° C) et  que Le réchauffement planétaire devrait atteindre 1,5° C entre 2030 et 2052, s’il continue à augmenter au rythme actuel. Ensuite sont exposées les conséquences d’un réchauffement de 1,5°C  par rapport à 2°C d’ici à 2100 : la montée du niveau des mers de 10 cm inférieure si le réchauffement est stabilisé à 1,5°C, une perte de biodiversité et de risque d’extinction d’espèces réduites d’un facteur 2, une réduction du rendement des céréales moins important, des pénuries d’eau deux fois moindre, une dégradation des récifs de coraux tropicaux limitée à une fourchette de 70% à 90%, au lieu de 99%. Le site Carbon Brief  a réalisé une infographie permettant de visualiser les conséquences d’un réchauffement de 1,5°C par rapport à 2°C. Enfin le rapport quantifie la réduction de nos émission de CO2 d’ici 2030 nécessaire pour limiter le réchauffement à 1,5°C :  une diminution de 45% contre 20% si nous nous laissions aller à un échauffement de 2°C. Il  faudra pour cela extraire le CO2  de l’atmosphère tout au long du 21e  siècle : en plantant des arbres, restaurant  les écosystèmes, captant et stockant le CO2  , et aussi en utilisant d’autres approches qui en sont aujourd’hui aux premières étapes de développement , nous dit Valérie Masson – Delmotte (et dont tout porte à penser qu’il pourrait s’agir de techniques de géo-ingénierie). On reste pantois devant une telle précision dans l’évaluation des conséquences d’une différence de température de 0,5°C qui se situe dans l’intervalle de confiance des prévisions.  Le Président de la République Française a salué l’exploit des scientifiques par ce tweet : « Le rapport du GIEC le prouve scientifiquement: nous avons toutes les cartes en main pour lutter contre le réchauffement climatique. Mais il faut que tout le monde agisse maintenant ! ». Sauf que ce rapport est tout sauf de la science, comme nous allons essayer de le montrer. Remarquons d’abord que le résumé pour décideurs n’est pas une production scientifique mais un compromis politique. Madame Valérie Masson-Delmotte avait déjà en 2013 à propos du 5e rapport du GIEC, très bien expliqué comment s’élabore un rapport pour décideurs : « L’enjeu était de se mettre autour de la table pour approuver, mot par mot, le résumé pour décideurs   par l’assemblée des délégués des différents pays » déclarait-t-elle au journal  Le Point.  On relève ensuite que pour l’élaboration de ce rapport spécial, le GIEC a fait travailler ensemble ses 3 groupes de travail [1]. C’est le « premier rapport du GIEC où climatologues, spécialistes des impacts climatiques et scientifiques experts de l’atténuation ont travaillé ensemble », a dit au Figaro Roland Séférian, chercheur chez Météo-France. Cet aveu a un sens : Il signifie que le réchauffement récent est définitivement imputé aux activité humaines, et qu’il n’est donc plus nécessaire d’étudier les causes naturelles possibles : cycles solaires, nébulosité, oscillations océaniques, etc..La science est  établie, il ne reste qu’à s’occuper des conséquences du réchauffement et des mesures à prendre pour l’atténuer. Le GIEC peut-il régler le thermostat de la planète ? Prévoir la hausse des températures mondiales en 2100 à l’aide des modèles climatiques est déjà hasardeux. Prétendre que l’on puisse ajuster les émissions pour limiter le réchauffement à 1,5°C  au lieu de 2°C relève du scientisme. Les prévisions climatiques à très long terme sont établies à l’aide de modèles dont le but est de reproduire le comportement du climat terrestre. Compte tenu de la diversité des processus à prendre en compte (rayonnement, convection, formation des nuages, fonte des glaciers, transpiration des plantes, ruissellement, infiltration des eaux dans le sol, etc.), de la multiplicité des échelles spatiales (du centimètre pour la turbulence de la couche limite à des ondulations de 10000 kilomètres pour les zones de haute et de basse pression) et temporelles (de la seconde pour les vagues de surface à plusieurs siècles pour les courants océaniques), et des interactions que les diverses parties du système climatique ont les unes sur les autres, l’entreprise des modélisateurs apparaît comme démiurgique.  Les processus climatiques qui sont mal compris (développement de nuages, turbulences, échanges avec la surface) sont introduits dans les modèles sous forme de paramètres ajustables (une dizaine) qui ont une signification statistique et compensent les incertitudes (lire au sujet des modèles cet article récemment publié sur ce site). De plus les modèles surchauffent. C’est ce qu’a montré J. C. Christy, Professeur à l’Université d’Alabama (Huntsville) au Sénat américain en 2016 : le diagramme ci-dessous qu’il a produit lors de son audition montre que sur les 38 dernières années l’écart entre la courbe de réchauffement des modèles et celle des données d’observation est très significatif démontrant que les modèles sont trop sensibles aux émissions de gaz à effet de serre :    Pierre Morel fondateur du Laboratoire de Météorologie Dynamique et ancien secrétaire général du programme mondial de recherche sur le climat lors d’une conférence au Bureau des Longitudes en octobre 2009, fustigeait les modélisateurs :
« Aucun modèle ne peut, en l’état actuel de l’art, représenter fidèlement la totalité des processus physiques en Jeu. Au contraire, ces modèles sont fondamentalement empiriques et font nécessairement appel à des paramètres arbitraires qui doivent être ajustés … Par conséquent, actuellement, les modèles de la science climatique théorique, tout cela est engagé sur une voie sans issue… malheureusement, les modélisateurs, qui ont une connaissance détaillée des codes numériques et formules physiques, n’ont plus une compréhension approfondie du fonctionnement de l’environnement réel dans tous ses aspects physiques. Je dois dire qu’il est facile de perdre de vue la multiplicité des processus dynamiques, physiques, chimiques, géologiques qui influencent le climat ». Dans quelle mesure les émissions anthropiques perturbent le cycle du carbone contribuant ainsi à l’augmentation de la concentration de CO2 dans l’atmosphère? De nombreuses incertitudes subsistent comme l’explique cet article. Pour en donner la mesure il suffit de mentionner ce fait (rapporté par Katia et Guy Laval dans leur ouvrage « Incertitudes sur le climat » [2] que, en vue de l’élaboration de son quatrième rapport, le GIEC a utilisé onze modèles qui devaient calculer la croissance de la concentration de CO2 dans l’atmosphère en 2100, après échanges avec les océans et la biosphère. Les résultats obtenus par les différents modèles de cycle du carbone présentaient une dispersion de 1 à 10 Au vu de ces incertitudes, le GIEC avait d’ailleurs choisi pour son rapport de 2013 de définir 4 valeurs préétablies de concentration de gaz à effet de serre (correspondant à ses 4 scenarios RCP « Representative Concentration Pathway ») plutôt que d’établir ses prévisions à partir de niveaux d’émission comme dans ses précédents rapports. Le GIEC s’était ainsi affranchi des incertitudes du cycle du carbone, comme cela est explicitement indiqué dans son rapport: « Les RCP utilisés dans le Rapport AR5 sont définis comme des profils de concentration et donc les incertitudes liées au cycle du carbone affectant les concentrations atmosphériques en CO2 ne sont pas prises en compte dans les simulations CMIP5 forcées par des concentrations ». (GIEC AR5 Résumé Pour Décideurs  Groupe de travail n° 1 (Page 18)). Aux incertitudes du cycle du carbone s’ajoutent celles de la sensibilité du climat [3] à l’augmentation des gaz à effet de serre. Il est admis (et cela n’est pas controversé) qu’un doublement de la concentration de CO2 n’induirait qu’une élévation de la température de l’ordre de 1°C. Le reste du réchauffement prévu par les modèles en 2100 (jusqu’à +4,8°) serait dû à un supposé effet amplificateur des nuages et de la vapeur d’eau ; or le comportement de la vapeur d’eau et des nuages (notamment les nuages bas) dans l’atmosphère est loin d’être complètement compris, ce que le GIEC admet dans son rapport de 2013 : « La plupart des modèles suppose une rétroaction positive des nuages bas, mais ce comportement n’est pas bien compris ; aussi nous ne sommes pas certains que cela est réaliste ». (Rapport AR5  [7.2.4, 7.2.5, 7.2.6, Figures 7.9–7.11]). Dans son ouvrage « Combien pèse un nuage? [4]» Jean-Pierre CHALON], Directeur de l’Ecole Nationale de la Météorologie, expert auprès de l’Organisation Météorologiste Mondiale, confirme l’incertitude due au comportement des nuages; il écrit : « l’impact global des nuages sur le bilan radiatif de la planète est 40 fois supérieur à celui attribué aux variations des teneurs en gaz à effet de serre enregistrées au cours de ces 10 dernières années ». Le climat est-il déréglé ?  « C’est de pire en pire»  a dit Laurence Tubiana ex-négociatrice de la COP21 à l’Express ; « Par exemple, sur le phénomène El Niño, qui était épisodique, il devient beaucoup plus régulier, tous les trois à quatre ans. De même aux pôles, on observe des zones qui deviennent accessibles à pied. La fonte des glaces, on ne pensait pas que ça irait aussi vite. Les coraux. Au-delà d’être jolis, ils sont indispensables aux poissons. Avec une hausse de 1,5 degré, on estime que le taux de survie serait de 66%. A 2 degrés, 90% disparaîtraient ». Examinons les phénomènes climatiques cités par Madame Tubiana. El Niño est un phénomène océanique à grande échelle du Pacifique équatorial qui a des répercussions sur le climat mondial pouvant  entraîner des tempêtes intenses à certains endroits et des sécheresses à d’autres. Les événements El Niño dont on retrouve des traces depuis des milliers d’années ne sont recensés et étudiés que depuis 1951. Ils se produisent  à intervalles irréguliers de deux à sept ans et durent de neuf mois à deux ans. La durée moyenne de la période est de cinq ans. Dans la période récente les événements les plus intenses se sont produits en 1982-1983, 1997-1998 et 2014-2016 (dont nous continuons à subir les effets). Il n’y a pas de consensus sur le fait de savoir si le changement climatique aura une influence sur la survenue, la force ou la durée des événements El Niño. Comme le dit avec ironie un expert de l’agence américaine NOAA  (National Oceanic and Atmospheric Administration). « Si vous souhaitez que les événements ENSO soient plus nombreux ou plus puissants à l’avenir, j’ai une excellente nouvelle pour vous : la recherche le prouve. Si vous souhaitez que les événements ENSO soient moins nombreux ou plus faibles dans le futur, ne vous inquiétez pas, la recherche le confirme également ». Le graphique ci-dessous montre la régularité de survenance des événements El Niño depuis 1950 :  Bien que sans influence sur le niveau des mers, la fonte annuelle de la banquise défraie la chronique, sa disparition étant fréquemment annoncée. Or contrairement  aux prévisions alarmistes, la banquise arctique qui avait régulièrement régressé depuis le début des années 1980 et atteint un point bas en 2007 et en 2012, se redresse: elle a atteint en 2018 son minimum d’extension (4.594 millions de km2) les 19 et 20 septembre, ce qui permet de classer l’année 2018 devant 2016, 2012 et 2012, Ex aequo avec les années 2017, 2015 et 2011 qui sont indiscernables.    Quant à la banquise antarctique, elle a été en progression constante jusqu’en 2015, année à partir de laquelle son étendue est passée sous la moyenne 1981-2010 :    Moins spectaculaire et donc moins commentée est l’évolution des glaces continentales pourtant plus importante dans ses conséquences : si les deux à trois kilomètres de glace qui couvrent le Groenland fondaient ou glissaient dans l’océan, le niveau des mers monterait d’environ six mètres. La fonte totale de l’Antarctique provoquerait quant à elle une hausse du niveau de la mer de l’ordre de 60 mètres. Qu’observe-t-on ? Au Groenland il neige plus qu’il ne fond au cours de l’année, le bilan de masse de surface est donc positif même si la perte par  vêlage des icebergs est supérieure au gain de bilan de masse de surface. Selon le DMI (Danish Meteorological Institute), le Groenland perdrait ainsi environ 200 Gt (Giga tonnes) par an. Rapporté au volume de glace estimé à 3 millions de kilomètres cubes (+ou- 0,4), la perte annuelle est de l’ordre de 0,007 % seulement. Cette perte serait surestimée selon D.H. Bromwich et J.-P. Nicolas (2010) qui ont ré analysé les données satellitaires de GRACE et divisé par 2 les pertes de glace du Groenland. Le site Polar Portal estime de son côté que le Groenland gagne en volume de glace par rapport à la moyenne 1981-2010. Le graphique ci-dessous montre l’évolution positive du bilan de glace SMB (surface mass budget) :  Source : Polar Portal ( http://polarportal.dk/en/nyheder/arkiv/nyheder/end-of-the-smb-season-summary-2017/) L’inlandsis de l’Antarctique perdrait 100 km³ de glace par an d’après les mesures effectuées par les satellites de la mission GRACE. Cette valeur est à rapprocher des 30 millions de km³  de glace du continent antarctique. Selon une étude de la NASA (publiée en octobre 2015), les gains de masse de l’inlandsis antarctique sont supérieurs aux pertes remettant en cause les conclusions du 5e rapport du GIEC, selon lequel l’Antarctique est en train de perdre de la glace terrestre. La calotte glaciaire antarctique aurait ainsi enregistré un gain net de 112 milliards de tonnes de glace par an entre 1992 et 2001. Ce gain net serait tombé à 82 milliards de tonnes de glace par an entre 2003 et 2008. La même étude évalue la contribution de la fonte des glaces à l’élévation du niveau de la mer depuis 1992 à 0.59 ± 0.20 millimètres par année en moyenne (pour une élévation du niveau de la mer estimée à 3 millimètres par an selon les estimations les plus pessimistes). Il se produit en moyenne 300 catastrophes naturelles par an, soit presque une par jour ; nous en sommes informés en temps réel  et la responsabilité du réchauffement est presque systématiquement invoquée. Il se diffuse ainsi dans l’opinion l’idée d’un dérèglement climatique qui irait en s’accentuant sous l’effet du réchauffement. Or toutes les sources de données  (y compris celles du GIEC dans son rapport spécial sur les événements extrêmes de 2012, et dans son 5e rapport de 2013) sont convergentes : il n’y a pas d’augmentation de la fréquence , de l’intensité et de la durée des événements  extrêmes depuis le début de l’ère industrielle, qu’il s’agisse des cyclones et des tempêtes, des inondations, des sécheresses et des vagues de chaleur. Pour plus de détails, lire cet article qui a compilé de nombreuses sources de données dont celles de l’assureur AON qui produit tous les ans un rapport sur les désastres naturels.  Evolution du nombre de catastrophes naturelles. Source : AON, Weather, Climate & Catastrophe Insight (Rapport 2017) Les cyclones sont souvent cités comme une manifestation du dérèglement climatique en raison de leur caractère spectaculaire et récurrent. Or, comme le montre le diagramme ci-dessous il n’y a pas d’augmentation du nombre et de l’intensité des cyclones depuis 1980 :    Aux Etats-Unis, le nombre d’ouragans des 30 dernières années est en diminution comme le montre cet article. Ce qui est avéré en revanche, c’est l’augmentation continue de l’exposition aux risques (du fait notamment de l’augmentation de la population et de la tendance de celle ci à se concentrer dans des zones littorales). Jan Egeland , Secrétaire général du NRC (Norwegian Refugee Council) déclarait à l’occasion de la publication de son rapport de 2015 : « Les millions de vies dévastées par les catastrophes sont le plus souvent une conséquence de mauvaises politiques et de l’artificialisation des structures, que celle des forces de mère nature ». La Grande Barrière de Corail a connu pendant l’été 2016 un intense épisode de blanchiment qualifié par la NOAA de Troisième événement de blanchiment global . La mort des coraux de la grande barrière à cause du réchauffement climatique a été annoncée. Cette thèse est doublement spécieuse : d’une part, parce que le blanchiment de l’été 2016 (comme ceux qui l’ont précédé en 1998 et 2002) est lié à l’événement El Niño qui pour avoir été intense n’en n’est pas moins un événements climatiques naturel ; d’autre part parce que le blanchiment n’est pas et de loin la première cause de mortalité du corail arrivant loin derrière les cyclones et la prédation des étoiles de mer. Le professeur Peter Ridd, expert reconnu de la Grande Barrière de Corail estime non seulement que les coraux ne sont pas en perdition mais se remettent très bien des dégâts causés par les ouragans, les étoiles de mer et le blanchissement (ce qui lui a valu d’être ostracisé par son employeur, l’Université James Cook). Un article de ce site fait le point sur la situation de la Grande Barrière de Corail après la période de blanchissement de l’été 2016. Vers une « climatocrature » ? Le GIEC se pare des plumes de la science pour nous asséner ses prédictions catastrophistes, mais son message est en réalité politique. « chaque demi-degré de réchauffement compte, chaque année compte et chaque choix compte. Ne pas agir aujourd’hui, c’est augmenter le fardeau pour les jeunes générations qui devront faire face aux conséquences du réchauffement et à des options d’action plus difficiles et plus risquées », a dit Madame Valérie Masson-Delmotte lors de son audition par le Sénat. Chacun voit bien que ce qu’elle demande à la société sur des bases scientifiques plus que fragiles (une réduction de 50% de nos émissions d’ici 2030), n’est ni souhaitable ni possible, sauf à être imposé par la coercition. Coercition que certains scientifiques appellent de leurs vœux : ainsi François-Marie Bréon  directeur adjoint du laboratoire des sciences du climat et de l’environnement (LSCE), et qui propose des mesures radicales à dit à Libération : « On peut dire que la lutte contre le changement climatique est contraire aux libertés individuelles et donc sans doute avec la démocratie ». Supposons que l’on réduise nos émissions de 50% au prix d’une révision radicale de notre modèle de développement, (et de l’instauration d’un ordre mondial autoritaire pour l’imposer). Nous nous serions privés de nos capacités industrielles pour faire face (par exemple) à un nouveau petit âge glaciaire : l’hypothèse n’est pas totalement fantaisiste comme l’indique une récente publication de la Royal Astronomical Society  qui prévoit une réduction de l’activité solaire de 60% lors du 26e cycle du soleil (2030-2040) [5]. [1] Le GIEC est organisé en 3 groupes de travail : le premier (GR1) évalue les aspects scientifiques du système climatique et de )l’évolution du climat; le deuxième (GR2) traite des conséquences changements climatiques et les possibilités de s’y adapter; le troisième évalue les solutions envisageables pour atténuer les conséquences des changements climatiques. [2] Incertitudes sur le climat (Katia Laval, Guy Laval) Editeur :Belin (https://www.belin-editeur.com/incertitudes-sur-le-climat) [3] La sensibilité est définie comme le changement de la température moyenne du globe en surface sous l’effet d’un doublement de la concentration du CO2 atmosphérique. [4] « J.P. Chalon « Combien pèse un nuage? – EDP Sciences [5] Selon cette étude, les conditions d’un nouveau « minimum de Maunder » (1645-1715) seraient réunies.   